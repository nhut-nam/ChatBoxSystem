[2025-10-01 17:38:08,705: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 17:38:08,716: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 17:38:08,718: INFO: helper]: Directory created at: artifacts
[2025-10-01 17:38:09,392: ERROR: 2326871357]: [WinError 3] The system cannot find the path specified: 'artifacts\\data_ingestion'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_11956\2326871357.py", line 6, in <module>
    data_ingestion.download_file()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_11956\342449326.py", line 7, in download_file
    gdown.download(self.config.source_URL, str(self.config.local_data_file), quiet=False)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\gdown\download.py", line 304, in download
    for file in os.listdir(osp.dirname(output) or "."):
FileNotFoundError: [WinError 3] The system cannot find the path specified: 'artifacts\\data_ingestion'
[2025-10-01 17:39:17,331: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 17:39:17,331: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 17:39:17,331: INFO: helper]: Directory created at: artifacts
[2025-10-01 17:39:17,331: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 17:39:18,248: INFO: 342449326]: File downloaded successfully and saved to artifacts\data_ingestion\chat_data.csv
[2025-10-01 17:39:18,518: ERROR: 2326871357]: Error tokenizing data. C error: Expected 1 fields in line 3, saw 4274
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_27116\2326871357.py", line 7, in <module>
    data_ingestion.data_augmentation()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_27116\342449326.py", line 14, in data_augmentation
    df = pd.read_csv(self.config.local_data_file)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\pandas\io\parsers\readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\pandas\io\parsers\readers.py", line 626, in _read
    return parser.read(nrows)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\pandas\io\parsers\readers.py", line 1923, in read
    ) = self._engine.read(  # type: ignore[attr-defined]
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\pandas\io\parsers\c_parser_wrapper.py", line 234, in read
    chunks = self._reader.read_low_memory(nrows)
  File "pandas/_libs/parsers.pyx", line 838, in pandas._libs.parsers.TextReader.read_low_memory
  File "pandas/_libs/parsers.pyx", line 905, in pandas._libs.parsers.TextReader._read_rows
  File "pandas/_libs/parsers.pyx", line 874, in pandas._libs.parsers.TextReader._tokenize_rows
  File "pandas/_libs/parsers.pyx", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status
  File "pandas/_libs/parsers.pyx", line 2061, in pandas._libs.parsers.raise_parser_error
pandas.errors.ParserError: Error tokenizing data. C error: Expected 1 fields in line 3, saw 4274

[2025-10-01 17:45:44,267: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 17:45:44,269: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 17:45:44,270: INFO: helper]: Directory created at: artifacts
[2025-10-01 17:45:44,271: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 17:45:47,325: ERROR: 2326871357]: 'WindowsPath' object has no attribute 'write'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_27116\2326871357.py", line 6, in <module>
    data_ingestion.download_file()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_27116\3348649974.py", line 17, in download_file
    raise e
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_27116\3348649974.py", line 13, in download_file
    gdown.download(prefix + file_id, zip_download_dir)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\gdown\download.py", line 369, in download
    f.write(chunk)
AttributeError: 'WindowsPath' object has no attribute 'write'. Did you mean: 'drive'?
[2025-10-01 17:47:51,131: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 17:47:51,131: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 17:47:51,131: INFO: helper]: Directory created at: artifacts
[2025-10-01 17:47:51,131: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 17:47:53,279: INFO: 3348649974]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 17:47:53,379: ERROR: 2326871357]: 'Client' object has no attribute 'generate_text'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_23324\2326871357.py", line 7, in <module>
    data_ingestion.data_augmentation()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_23324\3348649974.py", line 25, in data_augmentation
    paraphrases = self.paraphrase_text(row['Answer'])
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_23324\3348649974.py", line 40, in paraphrase_text
    response = client.generate_text(
AttributeError: 'Client' object has no attribute 'generate_text'
[2025-10-01 17:50:00,339: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 17:50:00,341: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 17:50:00,342: INFO: helper]: Directory created at: artifacts
[2025-10-01 17:50:00,342: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 17:50:02,530: INFO: 466725409]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 17:50:02,530: ERROR: 2326871357]: DataIngestion.paraphrase_text() takes 1 positional argument but 2 were given
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14780\2326871357.py", line 7, in <module>
    data_ingestion.data_augmentation()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14780\466725409.py", line 25, in data_augmentation
    paraphrases = self.paraphrase_text(row['Answer'])
TypeError: DataIngestion.paraphrase_text() takes 1 positional argument but 2 were given
[2025-10-01 17:51:42,885: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 17:51:42,887: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 17:51:42,889: INFO: helper]: Directory created at: artifacts
[2025-10-01 17:51:42,889: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 17:51:45,270: INFO: 3051205662]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 17:51:45,327: ERROR: 2326871357]: 'Client' object has no attribute 'responses'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14780\2326871357.py", line 7, in <module>
    data_ingestion.data_augmentation()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14780\3051205662.py", line 25, in data_augmentation
    paraphrases = self.paraphrase_text(row['Answer'])
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14780\3051205662.py", line 42, in paraphrase_text
    response = client.responses.create(
AttributeError: 'Client' object has no attribute 'responses'
[2025-10-01 17:53:46,173: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 17:53:46,174: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 17:53:46,175: INFO: helper]: Directory created at: artifacts
[2025-10-01 17:53:46,176: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 17:53:48,391: INFO: 2648575987]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 17:53:48,414: ERROR: 2326871357]: Models.generate_content() got an unexpected keyword argument 'input'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14780\2326871357.py", line 7, in <module>
    data_ingestion.data_augmentation()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14780\2648575987.py", line 25, in data_augmentation
    paraphrases = self.paraphrase_text(row['Answer'])
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14780\2648575987.py", line 42, in paraphrase_text
    response = client.models.generate_content(
TypeError: Models.generate_content() got an unexpected keyword argument 'input'
[2025-10-01 17:54:01,345: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 17:54:01,346: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 17:54:01,347: INFO: helper]: Directory created at: artifacts
[2025-10-01 17:54:01,349: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 17:54:03,384: INFO: 318864275]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 17:54:03,416: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:54:34,665: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:54:34,668: ERROR: 2326871357]: 'GenerateContentResponse' object has no attribute 'output_text'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14780\2326871357.py", line 7, in <module>
    data_ingestion.data_augmentation()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14780\318864275.py", line 25, in data_augmentation
    paraphrases = self.paraphrase_text(row['Answer'])
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14780\318864275.py", line 48, in paraphrase_text
    paraphrases = [line.strip() for line in response.output_text.split("\n") if line.strip()]
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\pydantic\main.py", line 991, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'GenerateContentResponse' object has no attribute 'output_text'
[2025-10-01 17:55:33,408: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 17:55:33,409: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 17:55:33,410: INFO: helper]: Directory created at: artifacts
[2025-10-01 17:55:33,411: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 17:55:35,613: INFO: 1440940172]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 17:55:35,645: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:55:45,600: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:55:45,621: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:55:54,584: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:55:54,608: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:56:02,135: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:56:02,160: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:56:08,754: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:56:08,776: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:56:17,688: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:56:17,716: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:56:25,776: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:56:25,798: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:56:35,267: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:56:35,291: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:56:43,472: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:56:43,494: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:56:52,578: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:56:52,598: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:57:02,288: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:57:02,310: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:57:11,196: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:57:11,217: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:57:18,035: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:57:18,060: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:57:26,488: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:57:26,509: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:57:33,557: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:57:33,578: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:57:41,151: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:57:41,170: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:57:49,131: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:57:49,152: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:57:55,642: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:57:55,662: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:58:05,035: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:58:05,062: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:58:17,189: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:58:17,217: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:58:28,029: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:58:28,059: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:58:37,018: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:58:37,044: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:58:44,722: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:58:44,749: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:58:54,046: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:58:54,071: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:59:01,448: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:59:01,471: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:59:09,594: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:59:09,626: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:59:16,878: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:59:16,900: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:59:26,936: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:59:26,962: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:59:34,338: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:59:34,363: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:59:44,377: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:59:44,398: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 17:59:54,016: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 17:59:54,054: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:00:02,475: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:00:02,501: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:00:10,565: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:00:10,596: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:00:18,770: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:00:18,793: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:00:27,137: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:00:27,162: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:00:35,104: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:00:35,128: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:00:45,978: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:00:46,002: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:00:54,867: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:00:54,889: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:01:14,234: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:01:14,259: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:01:24,307: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:01:24,330: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:01:30,981: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:01:31,004: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:01:39,116: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:01:39,137: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:01:48,902: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:01:48,925: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:01:58,002: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:01:58,022: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:02:04,767: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:02:04,788: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:02:13,158: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:02:13,180: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:02:21,171: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:02:21,192: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:02:30,460: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:02:30,488: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:02:37,773: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:02:37,799: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:02:46,922: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:02:46,946: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 18:02:56,211: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 18:02:56,218: INFO: 1440940172]: Data augmentation completed and saved to artifacts/data_ingestion/data.csv
[2025-10-01 18:02:56,218: INFO: 2326871357]: Data ingestion completed successfully.
[2025-10-01 18:55:49,138: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 18:55:49,138: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 18:55:49,138: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 18:55:49,181: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 19:02:11,969: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 19:02:11,972: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 19:02:11,974: ERROR: 1568427099]: Error occurred: "'ConfigBox' object has no attribute 'root_dir'"
Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'root_dir'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'root_dir'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'root_dir'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\config_box.py", line 29, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'root_dir'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'root_dir'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'root_dir'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'root_dir'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26820\1568427099.py", line 2, in <module>
    config = ConfigurationManager()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26820\4019593451.py", line 9, in __init__
    create_directories([self.config.root_dir])
  File "box\\config_box.py", line 31, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'root_dir'"
[2025-10-01 19:02:53,082: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 19:02:53,084: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 19:02:53,085: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 19:02:53,085: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 19:02:53,087: ERROR: 1568427099]: Error occurred: "'ConfigBox' object has no attribute 'embeddings_file'"
Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'embeddings_file'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'embeddings_file'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'embeddings_file'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\config_box.py", line 29, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'embeddings_file'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'embeddings_file'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'embeddings_file'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'embeddings_file'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26820\1568427099.py", line 3, in <module>
    data_ingestion_config = config.get_data_ingestion_config()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26820\482523854.py", line 15, in get_data_ingestion_config
    embeddings_file=Path(self.config.embeddings_file),
  File "box\\config_box.py", line 31, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'embeddings_file'"
[2025-10-01 19:04:06,183: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 19:04:06,185: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 19:04:06,186: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 19:04:06,187: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 19:04:06,187: ERROR: 1568427099]: Error occurred: "'ConfigBox' object has no attribute 'model_name'"
Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'model_name'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'model_name'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'model_name'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\config_box.py", line 29, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'model_name'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'model_name'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'model_name'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'model_name'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26820\1568427099.py", line 3, in <module>
    data_ingestion_config = config.get_data_ingestion_config()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26820\1069021283.py", line 16, in get_data_ingestion_config
    model_name=self.config.model_name,
  File "box\\config_box.py", line 31, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'model_name'"
[2025-10-01 19:04:15,647: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 19:04:15,648: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 19:04:15,649: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 19:04:15,650: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 19:04:15,652: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 19:04:15,654: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 19:04:20,024: WARNING: file_download]: Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
[2025-10-01 19:04:26,753: INFO: 2983522759]: Loading data...
[2025-10-01 19:04:26,753: INFO: 2983522759]: Generating embeddings...
[2025-10-01 19:04:27,467: INFO: 2983522759]: Saving embeddings...
[2025-10-01 19:04:27,467: INFO: 2983522759]: Total embeddings indexed: 300
[2025-10-01 19:04:27,467: INFO: 2983522759]: Embeddings saved to artifacts\embeddings\embeddings.pkl
[2025-10-01 19:04:27,474: INFO: 1568427099]: Embeddings generation completed successfully.
[2025-10-01 20:23:48,796: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 20:23:48,797: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 20:23:48,798: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 20:23:48,954: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 20:23:49,011: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:23:49,013: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:23:49,015: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 20:23:49,016: ERROR: 1568427099]: Error occurred: 'ConfigurationManager' object has no attribute 'get_data_ingestion_config'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_12028\1568427099.py", line 3, in <module>
    data_ingestion_config = config.get_data_ingestion_config()
AttributeError: 'ConfigurationManager' object has no attribute 'get_data_ingestion_config'
[2025-10-01 20:24:15,546: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:24:15,547: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:24:15,548: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 20:24:15,549: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 20:24:15,553: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:24:15,553: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:24:20,122: INFO: 3818667061]: Loading data...
[2025-10-01 20:24:20,130: INFO: 3818667061]: Generating embeddings...
[2025-10-01 20:24:20,932: INFO: 3818667061]: Saving embeddings...
[2025-10-01 20:24:20,935: INFO: 3818667061]: Total embeddings indexed: 300
[2025-10-01 20:24:20,938: ERROR: 29449560]: Error occurred: Error in __cdecl faiss::FileIOWriter::FileIOWriter(const char *) at D:\a\faiss-wheels\faiss-wheels\third-party\faiss\faiss\impl\io.cpp:104: Error: 'f' failed: could not open artifacts\embeddings for writing: Permission denied
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_12028\29449560.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_12028\3818667061.py", line 14, in generate_embeddings
    self.save_embeddings(embeddings, texts)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_12028\3818667061.py", line 24, in save_embeddings
    faiss.write_index(index, str(self.config.embeddings_file))
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\faiss\swigfaiss_avx2.py", line 11267, in write_index
    return _swigfaiss_avx2.write_index(*args)
RuntimeError: Error in __cdecl faiss::FileIOWriter::FileIOWriter(const char *) at D:\a\faiss-wheels\faiss-wheels\third-party\faiss\faiss\impl\io.cpp:104: Error: 'f' failed: could not open artifacts\embeddings for writing: Permission denied
[2025-10-01 20:25:53,980: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:25:53,982: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:25:53,983: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 20:25:53,984: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 20:25:53,986: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:25:53,987: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:25:57,784: INFO: 3818667061]: Loading data...
[2025-10-01 20:25:57,784: INFO: 3818667061]: Generating embeddings...
[2025-10-01 20:25:58,448: INFO: 3818667061]: Saving embeddings...
[2025-10-01 20:25:58,450: INFO: 3818667061]: Total embeddings indexed: 300
[2025-10-01 20:25:58,450: INFO: 3818667061]: Embeddings saved to artifacts\embeddings\embeddings
[2025-10-01 20:25:58,450: INFO: 29449560]: Embeddings generation completed successfully.
[2025-10-01 20:43:27,687: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 20:43:27,687: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 20:43:27,687: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 20:43:27,826: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 20:43:27,882: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:43:27,883: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:43:27,884: INFO: helper]: Directory created at: artifacts
[2025-10-01 20:43:27,887: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:43:27,887: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:43:32,067: ERROR: 1193083817]: Error occurred: Error in __cdecl faiss::FileIOReader::FileIOReader(const char *) at D:\a\faiss-wheels\faiss-wheels\third-party\faiss\faiss\impl\io.cpp:70: Error: 'f' failed: could not open artifacts/embeddings/embeddings.index.index for reading: No such file or directory
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_5692\1193083817.py", line 7, in <module>
    retrieval = Retrieval(config=retrieval_config)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_5692\1200906793.py", line 5, in __init__
    self.index = faiss.read_index(self.config.embeddings_file + ".index")
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\faiss\swigfaiss_avx2.py", line 11273, in read_index
    return _swigfaiss_avx2.read_index(*args)
RuntimeError: Error in __cdecl faiss::FileIOReader::FileIOReader(const char *) at D:\a\faiss-wheels\faiss-wheels\third-party\faiss\faiss\impl\io.cpp:70: Error: 'f' failed: could not open artifacts/embeddings/embeddings.index.index for reading: No such file or directory
[2025-10-01 20:44:02,026: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:44:02,028: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:44:02,029: INFO: helper]: Directory created at: artifacts
[2025-10-01 20:44:02,031: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:44:02,032: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:44:05,836: ERROR: 1193083817]: Error occurred: 'str' object has no attribute 'with_suffix'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_5692\1193083817.py", line 7, in <module>
    retrieval = Retrieval(config=retrieval_config)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_5692\51609558.py", line 6, in __init__
    self.texts = np.load(self.config.embeddings_file.with_suffix('.npy'), allow_pickle=True)
AttributeError: 'str' object has no attribute 'with_suffix'
[2025-10-01 20:44:49,331: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 20:44:49,331: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 20:44:49,331: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 20:44:49,447: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 20:44:49,508: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:44:49,509: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:44:49,510: INFO: helper]: Directory created at: artifacts
[2025-10-01 20:44:49,512: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:44:49,512: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:44:53,578: ERROR: 1193083817]: Error occurred: Wrong number or type of arguments for overloaded function 'read_index'.
  Possible C/C++ prototypes are:
    faiss::read_index(char const *,int)
    faiss::read_index(char const *)
    faiss::read_index(FILE *,int)
    faiss::read_index(FILE *)
    faiss::read_index(faiss::IOReader *,int)
    faiss::read_index(faiss::IOReader *)
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_21060\1193083817.py", line 7, in <module>
    retrieval = Retrieval(config=retrieval_config)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_21060\51609558.py", line 5, in __init__
    self.index = faiss.read_index(self.config.embeddings_file)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\faiss\swigfaiss_avx2.py", line 11273, in read_index
    return _swigfaiss_avx2.read_index(*args)
TypeError: Wrong number or type of arguments for overloaded function 'read_index'.
  Possible C/C++ prototypes are:
    faiss::read_index(char const *,int)
    faiss::read_index(char const *)
    faiss::read_index(FILE *,int)
    faiss::read_index(FILE *)
    faiss::read_index(faiss::IOReader *,int)
    faiss::read_index(faiss::IOReader *)

[2025-10-01 20:45:50,970: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:45:50,972: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:45:50,972: INFO: helper]: Directory created at: artifacts
[2025-10-01 20:45:50,975: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:45:50,976: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:45:54,799: ERROR: 1193083817]: Error occurred: Wrong number or type of arguments for overloaded function 'read_index'.
  Possible C/C++ prototypes are:
    faiss::read_index(char const *,int)
    faiss::read_index(char const *)
    faiss::read_index(FILE *,int)
    faiss::read_index(FILE *)
    faiss::read_index(faiss::IOReader *,int)
    faiss::read_index(faiss::IOReader *)
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_21060\1193083817.py", line 7, in <module>
    retrieval = Retrieval(config=retrieval_config)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_21060\411801695.py", line 5, in __init__
    self.index = faiss.read_index(self.config.embeddings_file)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\faiss\swigfaiss_avx2.py", line 11273, in read_index
    return _swigfaiss_avx2.read_index(*args)
TypeError: Wrong number or type of arguments for overloaded function 'read_index'.
  Possible C/C++ prototypes are:
    faiss::read_index(char const *,int)
    faiss::read_index(char const *)
    faiss::read_index(FILE *,int)
    faiss::read_index(FILE *)
    faiss::read_index(faiss::IOReader *,int)
    faiss::read_index(faiss::IOReader *)

[2025-10-01 20:46:23,353: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:46:23,355: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:46:23,356: INFO: helper]: Directory created at: artifacts
[2025-10-01 20:46:23,358: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:46:23,359: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:46:27,129: ERROR: 1193083817]: Error occurred: [Errno 2] No such file or directory: 'artifacts/embeddings/embeddings.index.npy'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_21060\1193083817.py", line 7, in <module>
    retrieval = Retrieval(config=retrieval_config)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_21060\411801695.py", line 6, in __init__
    self.texts = np.load(self.config.embeddings_file + '.npy', allow_pickle=True)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\numpy\lib\_npyio_impl.py", line 451, in load
    fid = stack.enter_context(open(os.fspath(file), "rb"))
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts/embeddings/embeddings.index.npy'
[2025-10-01 20:47:01,210: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:47:01,212: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:47:01,213: INFO: helper]: Directory created at: artifacts
[2025-10-01 20:47:01,216: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:47:01,216: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:47:04,992: ERROR: 1193083817]: Error occurred: 'str' object has no attribute 'with_suffix'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_21060\1193083817.py", line 7, in <module>
    retrieval = Retrieval(config=retrieval_config)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_21060\3775476799.py", line 7, in __init__
    self.texts = np.load(self.config.embeddings_file.with_suffix('.npy'), allow_pickle=True)
AttributeError: 'str' object has no attribute 'with_suffix'
[2025-10-01 20:47:28,506: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:47:28,508: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:47:28,509: INFO: helper]: Directory created at: artifacts
[2025-10-01 20:47:28,512: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:47:28,513: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:47:32,268: INFO: 1193083817]: Retrieval completed successfully.
[2025-10-01 20:53:00,182: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:53:00,184: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:53:00,185: INFO: helper]: Directory created at: artifacts
[2025-10-01 20:53:00,188: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:53:00,189: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:53:04,185: INFO: 977177932]: Retrieval completed successfully.
[2025-10-01 20:53:23,868: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:53:23,868: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:53:23,868: INFO: helper]: Directory created at: artifacts
[2025-10-01 20:53:23,868: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:53:23,874: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:53:27,589: INFO: 2186049157]: Retrieval completed successfully.
[2025-10-01 20:55:16,970: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:55:16,972: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:55:16,972: INFO: helper]: Directory created at: artifacts
[2025-10-01 20:55:16,972: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:55:16,972: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:55:20,726: INFO: 1586978415]: Retrieval completed successfully.
[2025-10-01 20:56:57,974: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:56:57,975: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:56:57,977: INFO: helper]: Directory created at: artifacts
[2025-10-01 20:56:57,980: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:56:57,980: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:57:02,147: INFO: 1586978415]: Retrieval completed successfully.
[2025-10-01 20:57:40,268: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 20:57:40,269: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 20:57:40,270: INFO: helper]: Directory created at: artifacts
[2025-10-01 20:57:40,273: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 20:57:40,274: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 20:57:44,024: INFO: 1586978415]: Retrieval completed successfully.
[2025-10-01 21:00:05,298: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:00:05,298: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:00:05,298: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:00:05,304: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 21:00:05,305: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 21:00:09,790: INFO: 2634134274]: Retrieval completed successfully.
[2025-10-01 21:00:23,000: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:00:23,001: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:00:23,001: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:00:23,001: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 21:00:23,001: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 21:00:26,778: INFO: 508956482]: Retrieval completed successfully.
[2025-10-01 21:00:59,336: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:00:59,338: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:00:59,339: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:00:59,342: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 21:00:59,343: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 21:01:03,093: INFO: 2212425927]: Retrieval completed successfully.
[2025-10-01 21:01:41,100: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:01:41,102: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:01:41,103: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:01:41,105: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 21:01:41,106: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 21:01:44,935: INFO: 1801141296]: Retrieval completed successfully.
[2025-10-01 21:10:29,342: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 21:10:29,342: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 21:10:29,342: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 21:10:29,359: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 21:10:29,359: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-10-01 21:10:29,359: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:10:29,359: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:10:29,359: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:10:29,359: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 21:10:32,070: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 21:10:32,086: ERROR: main]: >>>>>> stage Data Ingestion stage failed Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments. <<<<<<
[2025-10-01 21:10:32,086: INFO: main]: >>>>>> stage Embeddings stage started <<<<<<
[2025-10-01 21:10:32,086: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:10:32,086: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:10:32,086: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:10:32,086: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 21:10:32,086: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 21:10:32,086: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 21:10:36,664: INFO: embeddings]: Loading data...
[2025-10-01 21:10:36,664: INFO: embeddings]: Generating embeddings...
[2025-10-01 21:10:36,757: INFO: embeddings]: Saving embeddings...
[2025-10-01 21:10:36,758: INFO: embeddings]: Total embeddings indexed: 50
[2025-10-01 21:10:36,759: INFO: embeddings]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-01 21:10:36,759: INFO: stage_02_embeddings]: Embeddings generation completed successfully.
[2025-10-01 21:10:36,760: INFO: main]: >>>>>> stage Embeddings stage completed <<<<<<

x==========x
[2025-10-01 21:12:26,437: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 21:12:26,437: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 21:12:26,437: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 21:12:26,467: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 21:12:26,469: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-10-01 21:12:26,485: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:12:26,485: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:12:26,485: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:12:26,485: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 21:12:28,670: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 21:12:28,674: ERROR: main]: >>>>>> stage Data Ingestion stage failed Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments. <<<<<<
[2025-10-01 21:12:28,675: INFO: main]: >>>>>> stage Embeddings stage started <<<<<<
[2025-10-01 21:12:28,677: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:12:28,678: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:12:28,678: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:12:28,679: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 21:12:28,680: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 21:12:28,680: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 21:12:33,179: INFO: embeddings]: Loading data...
[2025-10-01 21:12:33,179: INFO: embeddings]: Generating embeddings...
[2025-10-01 21:12:33,263: INFO: embeddings]: Saving embeddings...
[2025-10-01 21:12:33,263: INFO: embeddings]: Total embeddings indexed: 50
[2025-10-01 21:12:33,265: INFO: embeddings]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-01 21:12:33,265: INFO: stage_02_embeddings]: Embeddings generation completed successfully.
[2025-10-01 21:12:33,265: INFO: main]: >>>>>> stage Embeddings stage completed <<<<<<

x==========x
[2025-10-01 21:14:54,183: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:14:54,185: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:14:54,187: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:14:54,188: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 21:14:55,946: INFO: 1440940172]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 21:14:56,013: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:16:07,758: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 21:16:07,758: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 21:16:07,758: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 21:16:07,764: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 21:16:07,786: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-10-01 21:16:07,786: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:16:07,786: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:16:07,786: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:16:07,786: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 21:16:09,886: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 21:16:09,886: ERROR: main]: >>>>>> stage Data Ingestion stage failed Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments. <<<<<<
[2025-10-01 21:16:09,886: INFO: main]: >>>>>> stage Embeddings stage started <<<<<<
[2025-10-01 21:16:09,893: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:16:09,893: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:16:09,893: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:16:09,893: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 21:16:09,893: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 21:16:09,893: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 21:16:14,399: INFO: embeddings]: Loading data...
[2025-10-01 21:16:14,399: INFO: embeddings]: Generating embeddings...
[2025-10-01 21:16:14,480: INFO: embeddings]: Saving embeddings...
[2025-10-01 21:16:14,480: INFO: embeddings]: Total embeddings indexed: 50
[2025-10-01 21:16:14,480: INFO: embeddings]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-01 21:16:14,480: INFO: stage_02_embeddings]: Embeddings generation completed successfully.
[2025-10-01 21:16:14,480: INFO: main]: >>>>>> stage Embeddings stage completed <<<<<<

x==========x
[2025-10-01 21:17:19,858: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 21:17:19,858: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 21:17:19,858: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 21:17:19,874: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 21:17:19,889: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-10-01 21:17:19,889: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:17:19,889: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:17:19,889: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:17:19,889: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 21:17:21,771: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 21:17:21,782: ERROR: main]: >>>>>> stage Data Ingestion stage failed Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments. <<<<<<
[2025-10-01 21:17:21,782: INFO: main]: >>>>>> stage Embeddings stage started <<<<<<
[2025-10-01 21:17:21,782: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:17:21,782: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:17:21,782: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:17:21,782: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 21:17:21,782: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 21:17:21,782: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 21:17:26,106: INFO: embeddings]: Loading data...
[2025-10-01 21:17:26,106: INFO: embeddings]: Generating embeddings...
[2025-10-01 21:17:26,189: INFO: embeddings]: Saving embeddings...
[2025-10-01 21:17:26,191: INFO: embeddings]: Total embeddings indexed: 50
[2025-10-01 21:17:26,191: INFO: embeddings]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-01 21:17:26,191: INFO: stage_02_embeddings]: Embeddings generation completed successfully.
[2025-10-01 21:17:26,191: INFO: main]: >>>>>> stage Embeddings stage completed <<<<<<

x==========x
[2025-10-01 21:18:33,848: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 21:18:33,849: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 21:18:33,850: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 21:18:33,866: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 21:18:33,874: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-10-01 21:18:33,876: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:18:33,878: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:18:33,878: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:18:33,878: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 21:18:35,635: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 21:18:35,700: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:18:56,983: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 21:18:56,983: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 21:18:56,983: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 21:18:56,999: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 21:18:57,015: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-10-01 21:18:57,015: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:18:57,015: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:18:57,015: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:18:57,015: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 21:18:58,875: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 21:18:58,939: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:19:10,248: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:19:10,285: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:19:24,213: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:19:24,251: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:19:38,962: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:19:38,994: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:19:53,573: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:19:53,605: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:20:10,052: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:20:10,068: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:20:24,673: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:20:24,709: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:20:38,905: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:20:38,931: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:20:48,693: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:20:48,724: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:21:01,571: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:21:01,602: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:21:06,521: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-10-01 21:21:06,522: ERROR: main]: >>>>>> stage Data Ingestion stage failed 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}} <<<<<<
[2025-10-01 21:21:06,523: INFO: main]: >>>>>> stage Embeddings stage started <<<<<<
[2025-10-01 21:21:06,526: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:21:06,527: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:21:06,527: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:21:06,529: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 21:21:06,534: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 21:21:06,534: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 21:21:13,058: INFO: embeddings]: Loading data...
[2025-10-01 21:21:13,058: INFO: embeddings]: Generating embeddings...
[2025-10-01 21:21:13,149: INFO: embeddings]: Saving embeddings...
[2025-10-01 21:21:13,150: INFO: embeddings]: Total embeddings indexed: 50
[2025-10-01 21:21:13,151: INFO: embeddings]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-01 21:21:13,151: INFO: stage_02_embeddings]: Embeddings generation completed successfully.
[2025-10-01 21:21:13,151: INFO: main]: >>>>>> stage Embeddings stage completed <<<<<<

x==========x
[2025-10-01 21:22:21,092: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 21:22:21,092: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 21:22:21,092: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 21:22:21,105: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 21:22:21,120: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-10-01 21:22:21,120: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:22:21,120: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:22:21,120: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:22:21,120: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 21:22:23,462: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 21:22:23,532: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:22:32,596: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:22:32,627: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:22:57,712: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:22:57,738: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:23:10,786: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:23:10,818: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:23:21,776: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:23:21,792: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:23:33,336: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:23:33,368: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:23:37,215: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-10-01 21:23:37,215: ERROR: main]: >>>>>> stage Data Ingestion stage failed 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}} <<<<<<
[2025-10-01 21:23:37,231: INFO: main]: >>>>>> stage Embeddings stage started <<<<<<
[2025-10-01 21:23:37,231: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:23:37,231: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:23:37,231: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:23:37,231: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 21:23:37,231: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 21:23:37,231: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 21:23:41,771: INFO: embeddings]: Loading data...
[2025-10-01 21:23:41,771: INFO: embeddings]: Generating embeddings...
[2025-10-01 21:23:41,859: INFO: embeddings]: Saving embeddings...
[2025-10-01 21:23:41,859: INFO: embeddings]: Total embeddings indexed: 50
[2025-10-01 21:23:41,859: INFO: embeddings]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-01 21:23:41,859: INFO: stage_02_embeddings]: Embeddings generation completed successfully.
[2025-10-01 21:23:41,859: INFO: main]: >>>>>> stage Embeddings stage completed <<<<<<

x==========x
[2025-10-01 21:37:30,175: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 21:37:30,175: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 21:37:30,175: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 21:37:30,191: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 21:37:30,207: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-10-01 21:37:30,207: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:37:30,223: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:37:30,223: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:37:30,223: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 21:37:32,624: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 21:37:32,688: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:37:42,863: ERROR: main]: >>>>>> stage Data Ingestion stage failed [SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1017) <<<<<<
[2025-10-01 21:37:42,863: INFO: main]: >>>>>> stage Embeddings stage started <<<<<<
[2025-10-01 21:37:42,863: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:37:42,863: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:37:42,863: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:37:42,863: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 21:37:42,863: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 21:37:42,863: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 21:37:47,298: INFO: embeddings]: Loading data...
[2025-10-01 21:37:47,314: INFO: embeddings]: Generating embeddings...
[2025-10-01 21:37:47,377: INFO: embeddings]: Saving embeddings...
[2025-10-01 21:37:47,377: INFO: embeddings]: Total embeddings indexed: 50
[2025-10-01 21:37:47,377: INFO: embeddings]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-01 21:37:47,377: INFO: stage_02_embeddings]: Embeddings generation completed successfully.
[2025-10-01 21:37:47,377: INFO: main]: >>>>>> stage Embeddings stage completed <<<<<<

x==========x
[2025-10-01 21:39:09,382: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 21:39:09,382: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 21:39:09,382: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 21:39:09,414: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 21:39:09,414: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-10-01 21:39:09,414: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:39:09,414: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:39:09,414: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:39:09,414: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 21:39:11,634: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 21:39:11,714: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:39:22,766: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:39:22,792: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:39:37,339: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:39:37,379: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:39:49,012: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:39:49,025: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:40:02,857: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:40:02,888: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:40:22,416: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:40:22,446: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:40:33,731: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 21:40:33,747: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 21:40:37,212: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-10-01 21:40:37,212: ERROR: main]: >>>>>> stage Data Ingestion stage failed 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}} <<<<<<
[2025-10-01 21:40:37,212: INFO: main]: >>>>>> stage Embeddings stage started <<<<<<
[2025-10-01 21:40:37,217: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 21:40:37,217: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 21:40:37,217: INFO: helper]: Directory created at: artifacts
[2025-10-01 21:40:37,217: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 21:40:37,217: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 21:40:37,217: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 21:40:41,508: INFO: embeddings]: Loading data...
[2025-10-01 21:40:41,508: INFO: embeddings]: Generating embeddings...
[2025-10-01 21:40:41,588: INFO: embeddings]: Saving embeddings...
[2025-10-01 21:40:41,588: INFO: embeddings]: Total embeddings indexed: 50
[2025-10-01 21:40:41,588: INFO: embeddings]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-01 21:40:41,588: INFO: stage_02_embeddings]: Embeddings generation completed successfully.
[2025-10-01 21:40:41,588: INFO: main]: >>>>>> stage Embeddings stage completed <<<<<<

x==========x
[2025-10-01 22:37:23,718: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 22:37:23,718: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 22:37:23,718: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 22:37:23,731: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 22:37:23,731: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-10-01 22:37:23,731: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 22:37:23,731: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 22:37:23,731: INFO: helper]: Directory created at: artifacts
[2025-10-01 22:37:23,731: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 22:37:26,008: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 22:37:26,087: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:37:38,839: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:37:38,855: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:37:53,005: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:37:53,043: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:38:06,675: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:38:06,707: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:38:16,427: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:38:16,459: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:38:25,671: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:38:25,687: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:38:37,017: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:38:37,038: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:38:50,041: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:38:50,069: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:39:01,409: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:39:01,448: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:39:12,152: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:39:12,180: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:39:24,005: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:39:24,022: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:39:35,215: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:39:35,245: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:39:45,529: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:39:45,547: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:39:54,329: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:39:54,361: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:40:02,608: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:40:02,640: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:40:13,134: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:40:13,150: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:40:27,370: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:40:27,386: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:40:38,485: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:40:38,517: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:41:07,685: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:41:07,701: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:41:19,593: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:41:19,609: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:41:29,682: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:41:29,713: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:41:40,980: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:41:40,995: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:41:49,851: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:41:49,867: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:42:00,492: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:42:00,524: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:42:15,388: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:42:15,420: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:42:21,469: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
[2025-10-01 22:42:21,471: ERROR: main]: >>>>>> stage Data Ingestion stage failed 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}} <<<<<<
[2025-10-01 22:42:21,471: INFO: main]: >>>>>> stage Embeddings stage started <<<<<<
[2025-10-01 22:42:21,471: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 22:42:21,471: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 22:42:21,471: INFO: helper]: Directory created at: artifacts
[2025-10-01 22:42:21,471: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 22:42:21,471: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 22:42:21,471: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 22:42:25,780: INFO: embeddings]: Loading data...
[2025-10-01 22:42:25,780: INFO: embeddings]: Generating embeddings...
[2025-10-01 22:42:25,864: INFO: embeddings]: Saving embeddings...
[2025-10-01 22:42:25,864: INFO: embeddings]: Total embeddings indexed: 50
[2025-10-01 22:42:25,864: INFO: embeddings]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-01 22:42:25,864: INFO: stage_02_embeddings]: Embeddings generation completed successfully.
[2025-10-01 22:42:25,864: INFO: main]: >>>>>> stage Embeddings stage completed <<<<<<

x==========x
[2025-10-01 22:48:09,778: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 22:48:09,778: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 22:48:09,778: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 22:48:09,794: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 22:48:09,794: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-10-01 22:48:09,794: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 22:48:09,794: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 22:48:09,810: INFO: helper]: Directory created at: artifacts
[2025-10-01 22:48:09,810: INFO: helper]: Directory created at: artifacts/data_ingestion
[2025-10-01 22:48:12,038: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/1AixdvjgwB0np9dIrxVJrmlzWI6AaDhwq/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.csv]
[2025-10-01 22:48:12,085: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:48:31,346: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:48:31,362: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:48:41,922: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:48:41,954: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:48:54,032: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:48:54,063: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:49:08,825: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:49:08,857: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:49:18,888: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:49:18,923: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:49:30,745: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:49:30,777: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:49:45,422: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:49:45,454: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:49:52,428: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:49:52,460: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:50:04,338: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:50:04,354: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:50:19,186: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:50:19,210: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:50:34,746: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:50:34,762: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:50:45,680: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:50:45,707: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:50:58,733: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:50:58,767: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:51:11,580: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:51:11,612: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:51:26,335: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:51:26,371: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:51:38,587: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:51:38,604: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:51:51,949: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:51:51,981: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:52:21,405: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:52:21,421: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:52:31,861: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:52:31,877: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:52:45,695: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:52:45,711: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:52:56,765: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:52:56,781: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:53:10,773: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:53:10,788: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:53:30,635: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:53:30,673: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:53:43,293: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:53:43,331: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:53:56,750: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:53:56,787: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:54:07,907: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:54:07,937: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:54:22,773: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:54:22,804: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:54:34,476: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:54:34,508: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:54:55,710: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:54:55,731: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:55:08,308: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:55:08,324: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:55:21,215: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:55:21,245: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:55:35,436: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:55:35,475: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:55:45,983: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:55:46,008: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:55:59,180: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:55:59,204: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:56:10,617: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:56:10,650: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:56:20,514: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:56:20,535: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:56:31,796: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:56:31,818: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:56:48,320: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:56:48,336: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:57:00,188: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:57:00,221: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:57:10,495: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:57:10,526: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:57:22,168: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:57:22,200: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:57:36,157: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:57:36,181: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:57:45,647: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:57:45,671: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:57:54,833: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:57:54,849: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:58:08,620: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:58:08,636: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:58:21,756: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:58:21,776: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:58:42,180: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:58:42,202: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:58:55,739: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:58:55,760: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:59:10,090: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:59:10,115: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 22:59:20,936: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 22:59:20,945: INFO: data_ingestion]: Data augmentation completed and saved to artifacts/data_ingestion/data.csv
[2025-10-01 22:59:20,946: INFO: stage_01_data_ingestion]: Data ingestion completed successfully.
[2025-10-01 22:59:20,946: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-10-01 22:59:20,946: INFO: main]: >>>>>> stage Embeddings stage started <<<<<<
[2025-10-01 22:59:20,948: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 22:59:20,949: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 22:59:20,949: INFO: helper]: Directory created at: artifacts
[2025-10-01 22:59:20,950: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-01 22:59:20,952: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 22:59:20,952: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 22:59:24,794: INFO: embeddings]: Loading data...
[2025-10-01 22:59:24,794: INFO: embeddings]: Generating embeddings...
[2025-10-01 22:59:25,923: INFO: embeddings]: Saving embeddings...
[2025-10-01 22:59:25,924: INFO: embeddings]: Total embeddings indexed: 550
[2025-10-01 22:59:25,924: INFO: embeddings]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-01 22:59:25,924: INFO: stage_02_embeddings]: Embeddings generation completed successfully.
[2025-10-01 22:59:25,924: INFO: main]: >>>>>> stage Embeddings stage completed <<<<<<

x==========x
[2025-10-01 23:00:12,003: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 23:00:12,003: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 23:00:12,019: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 23:00:12,139: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 23:00:12,218: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 23:00:12,220: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 23:00:12,221: INFO: helper]: Directory created at: artifacts
[2025-10-01 23:00:12,224: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 23:00:12,224: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 23:00:16,398: INFO: 1801141296]: Retrieval completed successfully.
[2025-10-01 23:00:48,685: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 23:00:48,685: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 23:00:48,685: INFO: helper]: Directory created at: artifacts
[2025-10-01 23:00:48,690: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 23:00:48,690: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 23:00:52,310: INFO: 2634134274]: Retrieval completed successfully.
[2025-10-01 23:15:13,338: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:15:16,219: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:15:51,702: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:15:53,121: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:16:09,025: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:16:21,240: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:42:55,074: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 23:42:55,074: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 23:42:55,074: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 23:42:55,103: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 23:42:55,111: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 23:42:55,114: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 23:42:55,114: INFO: helper]: Directory created at: artifacts
[2025-10-01 23:42:55,118: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 23:42:55,118: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 23:43:28,908: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 23:43:28,908: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 23:43:28,908: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 23:43:28,929: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 23:43:28,936: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 23:43:28,936: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 23:43:28,936: INFO: helper]: Directory created at: artifacts
[2025-10-01 23:43:28,936: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 23:43:28,936: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 23:43:32,766: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-01 23:43:32,766: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-01 23:43:53,699: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:43:53] "GET / HTTP/1.1" 200 -
[2025-10-01 23:43:54,292: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:43:54] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
[2025-10-01 23:47:21,807: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 23:47:21,807: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 23:47:21,807: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 23:47:21,823: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 23:47:21,823: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 23:47:21,823: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 23:47:21,823: INFO: helper]: Directory created at: artifacts
[2025-10-01 23:47:21,839: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 23:47:21,839: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 23:47:25,743: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-01 23:47:25,743: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-01 23:47:26,041: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:47:26] "GET / HTTP/1.1" 200 -
[2025-10-01 23:47:31,662: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:47:33,430: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:47:33,822: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:47:33,822: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:47:33] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:47:35,921: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:47:35,924: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:47:35] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:48:10,236: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 23:48:10,236: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 23:48:10,236: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 23:48:10,257: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 23:48:10,267: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 23:48:10,267: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 23:48:10,267: INFO: helper]: Directory created at: artifacts
[2025-10-01 23:48:10,267: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 23:48:10,267: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 23:48:14,126: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-01 23:48:14,126: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-01 23:48:19,176: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:48:19] "GET / HTTP/1.1" 200 -
[2025-10-01 23:48:20,799: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:48:22,922: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:48:22,937: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:48:22] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:48:34,538: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:48:35,303: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:48:39,116: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:48:39,116: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:48:39] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:48:44,386: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:48:44,386: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:48:44] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:49:01,866: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:49:03,351: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:49:03,351: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:49:03] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:50:09,186: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:50:10,653: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:50:10,653: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:50:10] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:51:01,588: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:51:05,294: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:51:05,294: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:51:05] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:51:19,161: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:51:22,398: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:51:22,399: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:51:22] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:51:46,118: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:51:47,739: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:51:49,591: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:51:49,607: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:51:49] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:51:51,005: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:51:51,005: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:51:51] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:52:33,977: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 23:52:33,977: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 23:52:33,977: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 23:52:34,094: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 23:52:34,163: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 23:52:34,165: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 23:52:34,166: INFO: helper]: Directory created at: artifacts
[2025-10-01 23:52:34,169: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 23:52:34,170: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 23:52:38,014: INFO: 2333845701]: Retrieval completed successfully.
[2025-10-01 23:54:28,669: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 23:54:28,669: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 23:54:28,670: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 23:54:28,687: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 23:54:28,691: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 23:54:28,691: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 23:54:28,691: INFO: helper]: Directory created at: artifacts
[2025-10-01 23:54:28,691: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 23:54:28,691: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 23:54:32,984: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-01 23:54:32,985: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-01 23:54:33,003: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:54:33] "GET / HTTP/1.1" 200 -
[2025-10-01 23:54:43,317: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:54:45,993: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:54:46,007: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:54:46] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:54:58,919: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:55:05,322: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:55:05,322: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:55:05] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:56:07,736: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 23:56:07,736: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 23:56:07,736: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 23:56:07,753: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 23:56:07,760: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 23:56:07,761: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 23:56:07,762: INFO: helper]: Directory created at: artifacts
[2025-10-01 23:56:07,765: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 23:56:07,766: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 23:56:11,684: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-01 23:56:11,685: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-01 23:56:17,521: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:56:17] "GET / HTTP/1.1" 200 -
[2025-10-01 23:56:29,169: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:56:30,256: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:56:31,134: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:56:31,137: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:56:31] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:56:32,511: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:56:32,512: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:56:32] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:56:47,720: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:56:51,521: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:56:51,525: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:56:51] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:57:46,796: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 23:57:46,796: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 23:57:46,797: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 23:57:46,820: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 23:57:46,829: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 23:57:46,830: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 23:57:46,831: INFO: helper]: Directory created at: artifacts
[2025-10-01 23:57:46,833: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 23:57:46,833: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 23:57:50,746: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-01 23:57:50,747: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-01 23:57:54,105: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:57:54] "GET / HTTP/1.1" 200 -
[2025-10-01 23:58:05,486: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:58:11,486: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:58:11,488: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:58:11] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:58:38,979: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-01 23:58:44,198: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-01 23:58:44,202: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:58:44] "POST /ask HTTP/1.1" 200 -
[2025-10-01 23:59:48,144: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-01 23:59:48,144: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-01 23:59:48,144: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-01 23:59:48,164: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-01 23:59:48,177: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-01 23:59:48,178: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-01 23:59:48,178: INFO: helper]: Directory created at: artifacts
[2025-10-01 23:59:48,182: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-01 23:59:48,182: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-01 23:59:52,169: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-01 23:59:52,169: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-01 23:59:54,656: INFO: _internal]: 127.0.0.1 - - [01/Oct/2025 23:59:54] "GET / HTTP/1.1" 200 -
[2025-10-01 23:59:56,179: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:00:01,588: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:00:01,593: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:00:01] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:01:26,639: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 00:01:26,640: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 00:01:26,640: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 00:01:26,658: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 00:01:26,668: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 00:01:26,668: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 00:01:26,669: INFO: helper]: Directory created at: artifacts
[2025-10-02 00:01:26,670: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-02 00:01:26,671: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-02 00:01:30,584: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-02 00:01:30,584: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-02 00:01:31,302: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:01:31] "GET / HTTP/1.1" 200 -
[2025-10-02 00:01:43,244: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:01:44,567: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:01:44,583: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:01:44] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:02:17,271: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:02:20,546: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:02:20,547: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:02:20] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:04:18,075: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 00:04:18,075: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 00:04:18,075: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 00:04:18,089: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 00:04:18,089: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 00:04:18,089: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 00:04:18,089: INFO: helper]: Directory created at: artifacts
[2025-10-02 00:04:18,089: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-02 00:04:18,089: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-02 00:04:22,615: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-02 00:04:22,615: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-02 00:04:25,315: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:04:25] "GET / HTTP/1.1" 200 -
[2025-10-02 00:04:33,122: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:04:35,566: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:04:35,571: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:04:35] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:04:46,740: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:04:51,908: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:04:51,908: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:04:51] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:07:16,717: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 00:07:16,717: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 00:07:16,717: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 00:07:16,733: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 00:07:16,749: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 00:07:16,749: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 00:07:16,749: INFO: helper]: Directory created at: artifacts
[2025-10-02 00:07:16,749: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-02 00:07:16,749: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-02 00:07:20,764: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-02 00:07:20,764: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-02 00:07:22,437: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:07:22] "GET / HTTP/1.1" 200 -
[2025-10-02 00:07:25,049: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:07:27,754: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:07:27,754: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:07:27] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:08:31,295: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 00:08:31,295: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 00:08:31,295: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 00:08:31,315: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 00:08:31,332: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 00:08:31,332: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 00:08:31,332: INFO: helper]: Directory created at: artifacts
[2025-10-02 00:08:31,332: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-02 00:08:31,332: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-02 00:08:35,240: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-02 00:08:35,240: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-02 00:08:36,989: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:08:36] "GET / HTTP/1.1" 200 -
[2025-10-02 00:08:39,583: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:08:45,080: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:08:45,097: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:08:45] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:09:51,494: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 00:09:51,494: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 00:09:51,494: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 00:09:51,510: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 00:09:51,526: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 00:09:51,526: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 00:09:51,526: INFO: helper]: Directory created at: artifacts
[2025-10-02 00:09:51,526: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-02 00:09:51,526: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-02 00:09:55,450: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-02 00:09:55,450: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-02 00:09:57,330: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:09:57] "GET / HTTP/1.1" 200 -
[2025-10-02 00:09:59,696: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:10:02,921: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:10:02,924: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:10:02] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:10:22,763: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:10:23,585: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:10:24,185: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:10:24,192: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:10:24] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:10:27,533: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:10:27,533: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:10:27] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:10:45,324: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:10:47,705: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:10:47,705: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:10:47] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:12:25,247: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 00:12:25,247: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 00:12:25,247: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 00:12:25,263: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 00:12:25,280: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 00:12:25,280: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 00:12:25,280: INFO: helper]: Directory created at: artifacts
[2025-10-02 00:12:25,280: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-02 00:12:25,280: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-02 00:12:30,046: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-02 00:12:30,046: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-02 00:12:31,739: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:12:31] "GET / HTTP/1.1" 200 -
[2025-10-02 00:12:46,444: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:12:46] "GET / HTTP/1.1" 200 -
[2025-10-02 00:12:58,499: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 00:12:58,500: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 00:12:58,500: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 00:12:58,519: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 00:12:58,529: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 00:12:58,530: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 00:12:58,530: INFO: helper]: Directory created at: artifacts
[2025-10-02 00:12:58,532: INFO: SentenceTransformer]: Use pytorch device_name: cpu
[2025-10-02 00:12:58,532: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: all-MiniLM-L6-v2
[2025-10-02 00:13:02,792: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-02 00:13:02,792: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-02 00:13:05,284: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:13:05] "GET / HTTP/1.1" 200 -
[2025-10-02 00:13:18,786: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:13:30,527: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:13:30,527: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:13:30] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:13:43,302: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:13:45,048: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:13:45,064: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:13:45] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:14:35,391: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:14:38,120: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:14:38,120: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:14:38] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:16:09,601: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:16:26,510: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:16:26,510: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:16:26] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:18:11,027: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:18:14,043: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:18:14,043: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:18:14] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:18:36,928: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:18:39,698: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:18:39,700: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:18:39] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:19:23,018: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:19:26,600: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:19:26,616: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:19:26] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:20:13,619: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:20:16,691: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:20:16,691: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:20:16] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:20:52,101: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:20:57,804: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:20:57,820: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:20:57] "POST /ask HTTP/1.1" 200 -
[2025-10-02 00:21:35,967: INFO: models]: AFC is enabled with max remote calls: 10.
[2025-10-02 00:21:43,374: INFO: _client]: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
[2025-10-02 00:21:43,375: INFO: _internal]: 127.0.0.1 - - [02/Oct/2025 00:21:43] "POST /ask HTTP/1.1" 200 -
[2025-10-02 06:42:47,491: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 06:42:47,493: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 06:42:47,494: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 06:42:47,653: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 07:02:23,910: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 07:02:23,910: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 07:02:23,910: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 07:02:23,944: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 07:02:51,929: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:02:51,931: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:02:51,932: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:02:51,934: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:02:51,935: INFO: 1122261269]: Loading data...
[2025-10-02 07:02:51,940: ERROR: 3935594119]: Error occurred: 'question'
Traceback (most recent call last):
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\pandas\core\indexes\base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\\_libs\\hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas\\_libs\\hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'question'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14208\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14208\1122261269.py", line 10, in generate_embeddings
    q, a = row["question"], row["answer"]
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\pandas\core\series.py", line 1121, in __getitem__
    return self._get_value(key)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\pandas\core\series.py", line 1237, in _get_value
    loc = self.index.get_loc(label)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\pandas\core\indexes\base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'question'
[2025-10-02 07:03:07,781: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:03:07,783: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:03:07,784: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:03:07,785: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:03:07,785: INFO: 2166179187]: Loading data...
[2025-10-02 07:03:07,822: INFO: 2166179187]: Generating embeddings...
[2025-10-02 07:03:08,696: ERROR: 3935594119]: Error occurred: 
******
Could not load OpenAI embedding model. If you intended to use OpenAI, please check your OPENAI_API_KEY.
Original error:
No API key found for OpenAI.
Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.
API keys can be found or created at https://platform.openai.com/account/api-keys

Consider using embed_model='local'.
Visit our documentation for more embedding options: https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html#modules
******
Traceback (most recent call last):
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\embeddings\utils.py", line 59, in resolve_embed_model
    validate_openai_api_key(embed_model.api_key)  # type: ignore
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\utils.py", line 104, in validate_openai_api_key
    raise ValueError(MISSING_API_KEY_ERROR_MESSAGE)
ValueError: No API key found for OpenAI.
Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.
API keys can be found or created at https://platform.openai.com/account/api-keys


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14208\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14208\2166179187.py", line 15, in generate_embeddings
    embeddings = VectorStoreIndex.from_documents(documents)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 122, in from_documents
    return cls(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 71, in __init__
    embed_model or Settings.embed_model, callback_manager=callback_manager
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\settings.py", line 64, in embed_model
    self._embed_model = resolve_embed_model("default")
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\embeddings\utils.py", line 66, in resolve_embed_model
    raise ValueError(
ValueError: 
******
Could not load OpenAI embedding model. If you intended to use OpenAI, please check your OPENAI_API_KEY.
Original error:
No API key found for OpenAI.
Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.
API keys can be found or created at https://platform.openai.com/account/api-keys

Consider using embed_model='local'.
Visit our documentation for more embedding options: https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html#modules
******
[2025-10-02 07:05:03,489: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:05:03,490: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:05:03,491: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:05:03,492: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:05:03,492: INFO: 2166179187]: Loading data...
[2025-10-02 07:05:03,528: INFO: 2166179187]: Generating embeddings...
[2025-10-02 07:05:03,605: ERROR: 3935594119]: Error occurred: 
******
Could not load OpenAI embedding model. If you intended to use OpenAI, please check your OPENAI_API_KEY.
Original error:
No API key found for OpenAI.
Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.
API keys can be found or created at https://platform.openai.com/account/api-keys

Consider using embed_model='local'.
Visit our documentation for more embedding options: https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html#modules
******
Traceback (most recent call last):
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\embeddings\utils.py", line 59, in resolve_embed_model
    validate_openai_api_key(embed_model.api_key)  # type: ignore
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\utils.py", line 104, in validate_openai_api_key
    raise ValueError(MISSING_API_KEY_ERROR_MESSAGE)
ValueError: No API key found for OpenAI.
Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.
API keys can be found or created at https://platform.openai.com/account/api-keys


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14208\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_14208\2166179187.py", line 15, in generate_embeddings
    embeddings = VectorStoreIndex.from_documents(documents)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 122, in from_documents
    return cls(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 71, in __init__
    embed_model or Settings.embed_model, callback_manager=callback_manager
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\settings.py", line 64, in embed_model
    self._embed_model = resolve_embed_model("default")
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\embeddings\utils.py", line 66, in resolve_embed_model
    raise ValueError(
ValueError: 
******
Could not load OpenAI embedding model. If you intended to use OpenAI, please check your OPENAI_API_KEY.
Original error:
No API key found for OpenAI.
Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.
API keys can be found or created at https://platform.openai.com/account/api-keys

Consider using embed_model='local'.
Visit our documentation for more embedding options: https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html#modules
******
[2025-10-02 07:06:41,745: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 07:06:41,748: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 07:06:41,749: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 07:06:41,880: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 07:06:47,043: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:06:47,045: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:06:47,045: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:06:47,046: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:06:47,047: INFO: 2166179187]: Loading data...
[2025-10-02 07:06:47,088: INFO: 2166179187]: Generating embeddings...
[2025-10-02 07:06:49,108: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 401 Unauthorized"
[2025-10-02 07:06:49,110: ERROR: 3935594119]: Error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: AIzaSyAW***************************QmjI. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26084\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26084\2166179187.py", line 15, in generate_embeddings
    embeddings = VectorStoreIndex.from_documents(documents)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 122, in from_documents
    return cls(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 75, in __init__
    super().__init__(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 79, in __init__
    index_struct = self.build_index_from_nodes(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 309, in build_index_from_nodes
    return self._build_index_from_nodes(content_nodes, **insert_kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 278, in _build_index_from_nodes
    self._add_nodes_to_index(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 231, in _add_nodes_to_index
    nodes_batch = self._get_node_with_embedding(nodes_batch, show_progress)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 138, in _get_node_with_embedding
    id_to_embed_map = embed_nodes(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\utils.py", line 176, in embed_nodes
    new_embeddings = embed_model.get_text_embedding_batch(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\embeddings\base.py", line 473, in get_text_embedding_batch
    embeddings = self._get_text_embeddings(cur_batch)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 472, in _get_text_embeddings
    return _retryable_get_embeddings()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 465, in _retryable_get_embeddings
    return get_embeddings(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 172, in get_embeddings
    data = client.embeddings.create(input=list_of_text, model=engine, **kwargs).data
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\resources\embeddings.py", line 132, in create
    return self._post(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: AIzaSyAW***************************QmjI. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
[2025-10-02 07:07:51,499: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:07:51,500: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:07:51,501: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:07:51,502: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:07:51,502: INFO: 2166179187]: Loading data...
[2025-10-02 07:07:51,536: INFO: 2166179187]: Generating embeddings...
[2025-10-02 07:07:52,103: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 401 Unauthorized"
[2025-10-02 07:07:52,103: ERROR: 3935594119]: Error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: AIzaSyAW***************************QmjI. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26084\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26084\2166179187.py", line 15, in generate_embeddings
    embeddings = VectorStoreIndex.from_documents(documents)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 122, in from_documents
    return cls(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 75, in __init__
    super().__init__(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 79, in __init__
    index_struct = self.build_index_from_nodes(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 309, in build_index_from_nodes
    return self._build_index_from_nodes(content_nodes, **insert_kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 278, in _build_index_from_nodes
    self._add_nodes_to_index(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 231, in _add_nodes_to_index
    nodes_batch = self._get_node_with_embedding(nodes_batch, show_progress)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 138, in _get_node_with_embedding
    id_to_embed_map = embed_nodes(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\utils.py", line 176, in embed_nodes
    new_embeddings = embed_model.get_text_embedding_batch(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\embeddings\base.py", line 473, in get_text_embedding_batch
    embeddings = self._get_text_embeddings(cur_batch)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 472, in _get_text_embeddings
    return _retryable_get_embeddings()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 465, in _retryable_get_embeddings
    return get_embeddings(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 172, in get_embeddings
    data = client.embeddings.create(input=list_of_text, model=engine, **kwargs).data
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\resources\embeddings.py", line 132, in create
    return self._post(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: AIzaSyAW***************************QmjI. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
[2025-10-02 07:08:03,067: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:08:03,068: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:08:03,070: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:08:03,070: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:08:03,071: INFO: 2166179187]: Loading data...
[2025-10-02 07:08:03,106: INFO: 2166179187]: Generating embeddings...
[2025-10-02 07:08:03,654: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 401 Unauthorized"
[2025-10-02 07:08:03,654: ERROR: 3935594119]: Error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: AIzaSyAW***************************QmjI. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26084\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26084\2166179187.py", line 15, in generate_embeddings
    embeddings = VectorStoreIndex.from_documents(documents)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 122, in from_documents
    return cls(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 75, in __init__
    super().__init__(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 79, in __init__
    index_struct = self.build_index_from_nodes(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 309, in build_index_from_nodes
    return self._build_index_from_nodes(content_nodes, **insert_kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 278, in _build_index_from_nodes
    self._add_nodes_to_index(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 231, in _add_nodes_to_index
    nodes_batch = self._get_node_with_embedding(nodes_batch, show_progress)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 138, in _get_node_with_embedding
    id_to_embed_map = embed_nodes(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\utils.py", line 176, in embed_nodes
    new_embeddings = embed_model.get_text_embedding_batch(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\embeddings\base.py", line 473, in get_text_embedding_batch
    embeddings = self._get_text_embeddings(cur_batch)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 472, in _get_text_embeddings
    return _retryable_get_embeddings()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 465, in _retryable_get_embeddings
    return get_embeddings(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 172, in get_embeddings
    data = client.embeddings.create(input=list_of_text, model=engine, **kwargs).data
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\resources\embeddings.py", line 132, in create
    return self._post(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: AIzaSyAW***************************QmjI. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
[2025-10-02 07:08:29,315: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 07:08:29,315: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 07:08:29,315: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 07:08:29,454: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 07:08:30,792: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:08:30,792: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:08:30,792: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:08:30,792: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:08:30,798: INFO: 2166179187]: Loading data...
[2025-10-02 07:08:30,838: INFO: 2166179187]: Generating embeddings...
[2025-10-02 07:08:33,414: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:08:33,414: INFO: _base_client]: Retrying request to /embeddings in 0.467002 seconds
[2025-10-02 07:08:34,746: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:08:34,746: INFO: _base_client]: Retrying request to /embeddings in 0.874012 seconds
[2025-10-02 07:08:36,853: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:08:36,853: INFO: _base_client]: Retrying request to /embeddings in 1.767864 seconds
[2025-10-02 07:08:39,894: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:08:39,909: INFO: _base_client]: Retrying request to /embeddings in 3.673900 seconds
[2025-10-02 07:08:44,298: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:08:44,298: INFO: _base_client]: Retrying request to /embeddings in 6.381405 seconds
[2025-10-02 07:08:51,950: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:08:51,950: INFO: _base_client]: Retrying request to /embeddings in 7.099198 seconds
[2025-10-02 07:09:00,483: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:09:00,483: INFO: _base_client]: Retrying request to /embeddings in 7.511698 seconds
[2025-10-02 07:09:08,465: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:09:08,465: INFO: _base_client]: Retrying request to /embeddings in 7.028511 seconds
[2025-10-02 07:09:16,474: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:09:16,475: INFO: _base_client]: Retrying request to /embeddings in 7.053633 seconds
[2025-10-02 07:09:24,514: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:09:24,515: INFO: _base_client]: Retrying request to /embeddings in 7.112875 seconds
[2025-10-02 07:09:32,119: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:09:32,125: ERROR: 3935594119]: Error occurred: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_2336\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_2336\2166179187.py", line 15, in generate_embeddings
    embeddings = VectorStoreIndex.from_documents(documents)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 122, in from_documents
    return cls(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 75, in __init__
    super().__init__(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 79, in __init__
    index_struct = self.build_index_from_nodes(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 309, in build_index_from_nodes
    return self._build_index_from_nodes(content_nodes, **insert_kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 278, in _build_index_from_nodes
    self._add_nodes_to_index(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 231, in _add_nodes_to_index
    nodes_batch = self._get_node_with_embedding(nodes_batch, show_progress)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 138, in _get_node_with_embedding
    id_to_embed_map = embed_nodes(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\utils.py", line 176, in embed_nodes
    new_embeddings = embed_model.get_text_embedding_batch(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\embeddings\base.py", line 473, in get_text_embedding_batch
    embeddings = self._get_text_embeddings(cur_batch)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 472, in _get_text_embeddings
    return _retryable_get_embeddings()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 465, in _retryable_get_embeddings
    return get_embeddings(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 172, in get_embeddings
    data = client.embeddings.create(input=list_of_text, model=engine, **kwargs).data
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\resources\embeddings.py", line 132, in create
    return self._post(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[2025-10-02 07:12:04,133: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 07:12:04,135: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 07:12:04,136: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 07:12:04,260: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 07:12:05,550: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:12:05,551: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:12:05,551: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:12:05,551: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:12:05,551: INFO: 2166179187]: Loading data...
[2025-10-02 07:12:05,594: INFO: 2166179187]: Generating embeddings...
[2025-10-02 07:12:07,492: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:12:07,492: INFO: _base_client]: Retrying request to /embeddings in 0.483241 seconds
[2025-10-02 07:12:08,464: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:12:08,469: INFO: _base_client]: Retrying request to /embeddings in 0.885219 seconds
[2025-10-02 07:12:09,676: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:12:09,677: INFO: _base_client]: Retrying request to /embeddings in 1.644405 seconds
[2025-10-02 07:12:11,929: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:12:11,929: INFO: _base_client]: Retrying request to /embeddings in 3.149200 seconds
[2025-10-02 07:12:15,390: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:12:15,399: INFO: _base_client]: Retrying request to /embeddings in 6.900659 seconds
[2025-10-02 07:12:23,289: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:12:23,289: INFO: _base_client]: Retrying request to /embeddings in 7.496856 seconds
[2025-10-02 07:12:31,418: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:12:31,421: INFO: _base_client]: Retrying request to /embeddings in 6.483666 seconds
[2025-10-02 07:12:38,454: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:12:38,455: INFO: _base_client]: Retrying request to /embeddings in 6.168926 seconds
[2025-10-02 07:12:45,335: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:12:45,337: INFO: _base_client]: Retrying request to /embeddings in 7.742455 seconds
[2025-10-02 07:12:54,234: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:12:54,243: INFO: _base_client]: Retrying request to /embeddings in 6.292233 seconds
[2025-10-02 07:13:01,234: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:13:01,242: WARNING: before_sleep]: Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings in 1.0 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.
[2025-10-02 07:13:02,628: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:13:02,629: INFO: _base_client]: Retrying request to /embeddings in 0.378170 seconds
[2025-10-02 07:13:03,301: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:13:03,304: INFO: _base_client]: Retrying request to /embeddings in 0.798772 seconds
[2025-10-02 07:13:04,765: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:13:04,765: INFO: _base_client]: Retrying request to /embeddings in 1.622337 seconds
[2025-10-02 07:13:06,696: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:13:06,700: INFO: _base_client]: Retrying request to /embeddings in 3.122133 seconds
[2025-10-02 07:13:10,161: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:13:10,162: INFO: _base_client]: Retrying request to /embeddings in 7.875692 seconds
[2025-10-02 07:13:18,537: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:13:18,541: INFO: _base_client]: Retrying request to /embeddings in 6.979865 seconds
[2025-10-02 07:13:26,013: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:13:26,013: INFO: _base_client]: Retrying request to /embeddings in 7.520696 seconds
[2025-10-02 07:13:33,986: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:13:33,986: INFO: _base_client]: Retrying request to /embeddings in 6.863297 seconds
[2025-10-02 07:13:41,321: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:13:41,322: INFO: _base_client]: Retrying request to /embeddings in 7.511739 seconds
[2025-10-02 07:13:49,296: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:13:49,297: INFO: _base_client]: Retrying request to /embeddings in 7.663787 seconds
[2025-10-02 07:13:57,414: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:13:57,416: ERROR: 3935594119]: Error occurred: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\2166179187.py", line 15, in generate_embeddings
    embeddings = VectorStoreIndex.from_documents(documents)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 122, in from_documents
    return cls(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 75, in __init__
    super().__init__(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 79, in __init__
    index_struct = self.build_index_from_nodes(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 309, in build_index_from_nodes
    return self._build_index_from_nodes(content_nodes, **insert_kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 278, in _build_index_from_nodes
    self._add_nodes_to_index(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 231, in _add_nodes_to_index
    nodes_batch = self._get_node_with_embedding(nodes_batch, show_progress)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\base.py", line 138, in _get_node_with_embedding
    id_to_embed_map = embed_nodes(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\utils.py", line 176, in embed_nodes
    new_embeddings = embed_model.get_text_embedding_batch(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\embeddings\base.py", line 473, in get_text_embedding_batch
    embeddings = self._get_text_embeddings(cur_batch)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 472, in _get_text_embeddings
    return _retryable_get_embeddings()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 465, in _retryable_get_embeddings
    return get_embeddings(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 172, in get_embeddings
    data = client.embeddings.create(input=list_of_text, model=engine, **kwargs).data
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\resources\embeddings.py", line 132, in create
    return self._post(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[2025-10-02 07:14:52,336: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:14:52,337: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:14:52,338: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:14:52,339: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:14:52,340: INFO: 2757194065]: Loading data...
[2025-10-02 07:14:52,375: INFO: 2757194065]: Generating embeddings...
[2025-10-02 07:14:52,934: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:14:52,935: INFO: _base_client]: Retrying request to /embeddings in 0.489567 seconds
[2025-10-02 07:14:53,737: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:14:53,742: INFO: _base_client]: Retrying request to /embeddings in 0.880036 seconds
[2025-10-02 07:14:54,930: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:14:54,930: INFO: _base_client]: Retrying request to /embeddings in 1.540283 seconds
[2025-10-02 07:14:56,792: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:14:56,793: INFO: _base_client]: Retrying request to /embeddings in 3.270928 seconds
[2025-10-02 07:15:00,378: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:15:00,379: INFO: _base_client]: Retrying request to /embeddings in 7.538020 seconds
[2025-10-02 07:15:08,384: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:15:08,385: INFO: _base_client]: Retrying request to /embeddings in 6.950931 seconds
[2025-10-02 07:15:15,840: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:15:15,841: INFO: _base_client]: Retrying request to /embeddings in 7.422014 seconds
[2025-10-02 07:15:23,760: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:15:23,761: INFO: _base_client]: Retrying request to /embeddings in 7.262994 seconds
[2025-10-02 07:20:30,955: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:20:30,957: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:20:30,958: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:20:30,958: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:20:30,959: INFO: 1343863738]: Loading data...
[2025-10-02 07:20:30,995: INFO: 1343863738]: Generating embeddings...
[2025-10-02 07:20:30,996: ERROR: 3935594119]: Error occurred: Must provide either `input_dir` or `input_files`.
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\1343863738.py", line 16, in generate_embeddings
    embeddings = SimpleDirectoryReader().load_data_from_documents(documents)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\readers\file\base.py", line 271, in __init__
    raise ValueError("Must provide either `input_dir` or `input_files`.")
ValueError: Must provide either `input_dir` or `input_files`.
[2025-10-02 07:24:16,934: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:24:16,935: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:24:16,936: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:24:16,937: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:24:16,942: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:24:20,133: WARNING: file_download]: Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
[2025-10-02 07:24:27,465: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:24:27,465: INFO: 2243352284]: Loading data...
[2025-10-02 07:24:27,501: INFO: 2243352284]: Generating embeddings...
[2025-10-02 07:24:27,578: ERROR: 3935594119]: Error occurred: 1 validation error for EmbeddingEndEvent
chunks.0
  Input should be a valid string [type=string_type, input_value=['Question: What is your ...ystematize my routine.'], input_type=list]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\2243352284.py", line 17, in generate_embeddings
    embeddings = self.model.get_text_embedding([doc.text for doc in documents])
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\embeddings\base.py", line 391, in get_text_embedding
    EmbeddingEndEvent(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\pydantic\main.py", line 253, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 1 validation error for EmbeddingEndEvent
chunks.0
  Input should be a valid string [type=string_type, input_value=['Question: What is your ...ystematize my routine.'], input_type=list]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
[2025-10-02 07:24:59,207: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:24:59,209: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:24:59,210: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:24:59,210: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:24:59,212: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:25:03,760: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:25:03,760: INFO: 3745253957]: Loading data...
[2025-10-02 07:25:03,805: INFO: 3745253957]: Generating embeddings...
[2025-10-02 07:25:03,809: WARNING: base]: Embedding attempt failed: object of type 'Document' has no len()
[2025-10-02 07:25:07,823: WARNING: base]: Embedding attempt failed: object of type 'Document' has no len()
[2025-10-02 07:25:11,834: WARNING: base]: Embedding attempt failed: object of type 'Document' has no len()
[2025-10-02 07:25:11,835: ERROR: 3935594119]: Error occurred: object of type 'Document' has no len()
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3745253957.py", line 17, in generate_embeddings
    embeddings = self.model.get_text_embedding(documents)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\embeddings\base.py", line 368, in get_text_embedding
    text_embedding = self._get_text_embedding(text)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\huggingface\base.py", line 320, in _get_text_embedding
    return self._embed([text], prompt_name="text")[0]
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\huggingface\base.py", line 268, in _embed
    return self._embed_with_retry(inputs, prompt_name)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\huggingface\base.py", line 236, in _embed_with_retry
    emb = self._model.encode(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\torch\utils\_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1057, in encode
    length_sorted_idx = np.argsort([-self._text_length(sen) for sen in sentences])
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1057, in <listcomp>
    length_sorted_idx = np.argsort([-self._text_length(sen) for sen in sentences])
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 2050, in _text_length
    return sum([len(t) for t in text])  # Sum of length of individual strings
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 2050, in <listcomp>
    return sum([len(t) for t in text])  # Sum of length of individual strings
TypeError: object of type 'Document' has no len()
[2025-10-02 07:25:30,371: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:25:30,373: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:25:30,374: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:25:30,374: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:25:30,376: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:25:34,631: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:25:34,631: INFO: 874358710]: Loading data...
[2025-10-02 07:25:34,653: INFO: 874358710]: Generating embeddings...
[2025-10-02 07:25:34,693: ERROR: 3935594119]: Error occurred: 1 validation error for EmbeddingEndEvent
chunks.0
  Input should be a valid string [type=string_type, input_value=['Question: What is your ...tematize my routine.\n'], input_type=list]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\874358710.py", line 17, in generate_embeddings
    embeddings = self.model.get_text_embedding(documents)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\embeddings\base.py", line 391, in get_text_embedding
    EmbeddingEndEvent(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\pydantic\main.py", line 253, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 1 validation error for EmbeddingEndEvent
chunks.0
  Input should be a valid string [type=string_type, input_value=['Question: What is your ...tematize my routine.\n'], input_type=list]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
[2025-10-02 07:26:36,241: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:26:36,243: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:26:36,243: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:26:36,244: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:26:36,246: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:26:40,102: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:26:40,102: INFO: 4108204756]: Loading data...
[2025-10-02 07:26:40,127: INFO: 4108204756]: Generating embeddings...
[2025-10-02 07:26:40,165: ERROR: 3935594119]: Error occurred: 1 validation error for EmbeddingEndEvent
chunks.0
  Input should be a valid string [type=string_type, input_value=['Q', 'u', 'e', 's', 't',...i', 'n', 'e', '.', '\n'], input_type=list]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\4108204756.py", line 17, in generate_embeddings
    embeddings = self.model.get_text_embedding(documents)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\embeddings\base.py", line 391, in get_text_embedding
    EmbeddingEndEvent(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\pydantic\main.py", line 253, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 1 validation error for EmbeddingEndEvent
chunks.0
  Input should be a valid string [type=string_type, input_value=['Q', 'u', 'e', 's', 't',...i', 'n', 'e', '.', '\n'], input_type=list]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
[2025-10-02 07:26:59,053: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:26:59,055: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:26:59,056: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:26:59,056: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:26:59,058: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:27:02,623: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:27:02,623: INFO: 2419466722]: Loading data...
[2025-10-02 07:27:02,646: INFO: 2419466722]: Generating embeddings...
[2025-10-02 07:27:02,798: ERROR: 3935594119]: Error occurred: 'float' object has no attribute 'id_'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\2419466722.py", line 18, in generate_embeddings
    index = VectorStoreIndex.from_documents(embeddings)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 113, in from_documents
    docstore.set_document_hash(doc.id_, doc.hash)
AttributeError: 'float' object has no attribute 'id_'
[2025-10-02 07:27:59,391: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:27:59,393: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:27:59,394: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:27:59,395: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:27:59,398: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:28:03,211: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:28:03,212: INFO: 3330573590]: Loading data...
[2025-10-02 07:28:03,236: INFO: 3330573590]: Generating embeddings...
[2025-10-02 07:28:03,388: ERROR: 3935594119]: Error occurred: 'float' object has no attribute 'id_'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3330573590.py", line 18, in generate_embeddings
    index = VectorStoreIndex.from_documents(embeddings)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 113, in from_documents
    docstore.set_document_hash(doc.id_, doc.hash)
AttributeError: 'float' object has no attribute 'id_'
[2025-10-02 07:30:16,134: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:30:16,135: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:30:16,137: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:30:16,137: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:30:16,139: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:30:19,920: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:30:19,920: INFO: 3548739694]: Loading data...
[2025-10-02 07:30:19,960: INFO: 3548739694]: Generating embeddings via VectorStoreIndex...
[2025-10-02 07:30:24,133: INFO: 3548739694]: Saving VectorStoreIndex...
[2025-10-02 07:30:24,133: ERROR: 3935594119]: Error occurred: 'VectorStoreIndex' object has no attribute 'save_to_disk'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3548739694.py", line 20, in generate_embeddings
    self.save_embeddings(index)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3548739694.py", line 24, in save_embeddings
    index.save_to_disk(self.config.embeddings_file)
AttributeError: 'VectorStoreIndex' object has no attribute 'save_to_disk'
[2025-10-02 07:32:31,390: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:32:31,391: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:32:31,393: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:32:31,394: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:32:31,394: INFO: 3760180157]: Loading data...
[2025-10-02 07:32:31,427: INFO: 3760180157]: Generating embeddings via VectorStoreIndex...
[2025-10-02 07:32:31,428: ERROR: 3935594119]: Error occurred: 'Embeddings' object has no attribute 'model'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3760180157.py", line 17, in generate_embeddings
    index = VectorStoreIndex.from_documents(documents, embed_model=self.model)
AttributeError: 'Embeddings' object has no attribute 'model'
[2025-10-02 07:33:08,567: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:33:08,570: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:33:08,572: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:33:08,573: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:33:08,576: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:33:12,400: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:33:12,400: INFO: 1205035657]: Loading data...
[2025-10-02 07:33:12,440: INFO: 1205035657]: Generating embeddings via VectorStoreIndex...
[2025-10-02 07:33:16,374: INFO: 1205035657]: Saving VectorStoreIndex...
[2025-10-02 07:33:16,374: ERROR: 3935594119]: Error occurred: [Errno 2] No such file or directory: 'f:/ProjectAI/ChatSystem/artifacts/embeddings/docstore.json'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\1205035657.py", line 20, in generate_embeddings
    self.save_embeddings(index)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\1205035657.py", line 24, in save_embeddings
    storage_context = StorageContext.from_defaults(persist_dir=str(self.config.root_dir))
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\storage_context.py", line 113, in from_defaults
    docstore = docstore or SimpleDocumentStore.from_persist_dir(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\docstore\simple_docstore.py", line 62, in from_persist_dir
    return cls.from_persist_path(persist_path, namespace=namespace, fs=fs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\docstore\simple_docstore.py", line 81, in from_persist_path
    simple_kvstore = SimpleKVStore.from_persist_path(persist_path, fs=fs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\kvstore\simple_kvstore.py", line 55, in from_persist_path
    with fs.open(persist_path, "rb") as f:
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\spec.py", line 1338, in open
    f = self._open(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\implementations\local.py", line 210, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\implementations\local.py", line 387, in __init__
    self._open()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\implementations\local.py", line 392, in _open
    self.f = open(self.path, mode=self.mode)
FileNotFoundError: [Errno 2] No such file or directory: 'f:/ProjectAI/ChatSystem/artifacts/embeddings/docstore.json'
[2025-10-02 07:34:20,250: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:34:20,252: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:34:20,253: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:34:20,254: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:34:20,256: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:34:23,869: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:34:23,870: INFO: 920382490]: Loading data...
[2025-10-02 07:34:23,902: INFO: 920382490]: Generating embeddings via VectorStoreIndex...
[2025-10-02 07:34:27,661: INFO: 920382490]: Saving VectorStoreIndex...
[2025-10-02 07:34:27,661: ERROR: 3935594119]: Error occurred: [Errno 2] No such file or directory: 'f:/ProjectAI/ChatSystem/artifacts/embeddings/embeddings.index/docstore.json'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\920382490.py", line 20, in generate_embeddings
    self.save_embeddings(index)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\920382490.py", line 24, in save_embeddings
    storage_context = StorageContext.from_defaults(persist_dir=str(self.config.embeddings_file))
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\storage_context.py", line 113, in from_defaults
    docstore = docstore or SimpleDocumentStore.from_persist_dir(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\docstore\simple_docstore.py", line 62, in from_persist_dir
    return cls.from_persist_path(persist_path, namespace=namespace, fs=fs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\docstore\simple_docstore.py", line 81, in from_persist_path
    simple_kvstore = SimpleKVStore.from_persist_path(persist_path, fs=fs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\kvstore\simple_kvstore.py", line 55, in from_persist_path
    with fs.open(persist_path, "rb") as f:
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\spec.py", line 1338, in open
    f = self._open(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\implementations\local.py", line 210, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\implementations\local.py", line 387, in __init__
    self._open()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\implementations\local.py", line 392, in _open
    self.f = open(self.path, mode=self.mode)
FileNotFoundError: [Errno 2] No such file or directory: 'f:/ProjectAI/ChatSystem/artifacts/embeddings/embeddings.index/docstore.json'
[2025-10-02 07:37:04,176: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:37:04,178: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:37:04,179: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:37:04,180: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:37:04,182: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:37:08,197: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:37:08,197: INFO: 4154291455]: Loading data...
[2025-10-02 07:37:08,232: INFO: 4154291455]: Generating embeddings via VectorStoreIndex...
[2025-10-02 07:37:12,027: INFO: 4154291455]: Saving VectorStoreIndex...
[2025-10-02 07:37:12,027: ERROR: 3935594119]: Error occurred: [Errno 2] No such file or directory: 'f:/ProjectAI/ChatSystem/artifacts/embeddings/docstore.json'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\4154291455.py", line 20, in generate_embeddings
    self.save_embeddings(index)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\4154291455.py", line 25, in save_embeddings
    storage_context = StorageContext.from_defaults(persist_dir=str(self.config.root_dir))
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\storage_context.py", line 113, in from_defaults
    docstore = docstore or SimpleDocumentStore.from_persist_dir(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\docstore\simple_docstore.py", line 62, in from_persist_dir
    return cls.from_persist_path(persist_path, namespace=namespace, fs=fs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\docstore\simple_docstore.py", line 81, in from_persist_path
    simple_kvstore = SimpleKVStore.from_persist_path(persist_path, fs=fs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\kvstore\simple_kvstore.py", line 55, in from_persist_path
    with fs.open(persist_path, "rb") as f:
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\spec.py", line 1338, in open
    f = self._open(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\implementations\local.py", line 210, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\implementations\local.py", line 387, in __init__
    self._open()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\implementations\local.py", line 392, in _open
    self.f = open(self.path, mode=self.mode)
FileNotFoundError: [Errno 2] No such file or directory: 'f:/ProjectAI/ChatSystem/artifacts/embeddings/docstore.json'
[2025-10-02 07:38:43,702: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:38:43,703: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:38:43,703: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:38:43,705: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:38:43,707: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:38:47,513: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:38:47,513: INFO: 4154291455]: Loading data...
[2025-10-02 07:38:47,553: INFO: 4154291455]: Generating embeddings via VectorStoreIndex...
[2025-10-02 07:38:51,370: INFO: 4154291455]: Saving VectorStoreIndex...
[2025-10-02 07:38:51,370: ERROR: 3935594119]: Error occurred: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\3935594119.py", line 6, in <module>
    embeddings.generate_embeddings()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\4154291455.py", line 20, in generate_embeddings
    self.save_embeddings(index)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_1612\4154291455.py", line 25, in save_embeddings
    storage_context = StorageContext.from_defaults(persist_dir=str(self.config.root_dir))
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\storage_context.py", line 113, in from_defaults
    docstore = docstore or SimpleDocumentStore.from_persist_dir(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\docstore\simple_docstore.py", line 62, in from_persist_dir
    return cls.from_persist_path(persist_path, namespace=namespace, fs=fs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\docstore\simple_docstore.py", line 81, in from_persist_path
    simple_kvstore = SimpleKVStore.from_persist_path(persist_path, fs=fs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\kvstore\simple_kvstore.py", line 56, in from_persist_path
    data = json.load(f)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\json\__init__.py", line 293, in load
    return loads(fp.read(),
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
[2025-10-02 07:44:16,453: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:44:16,453: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:44:16,453: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:44:16,453: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:44:16,460: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:44:21,048: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:44:21,050: INFO: 2974174681]: Loading data...
[2025-10-02 07:44:21,081: INFO: 2974174681]: Generating embeddings via VectorStoreIndex...
[2025-10-02 07:44:24,961: INFO: 2974174681]: Saving VectorStoreIndex...
[2025-10-02 07:44:26,007: INFO: 2974174681]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-02 07:44:26,023: INFO: 3935594119]: Embeddings generation completed successfully.
[2025-10-02 07:46:18,621: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:46:18,622: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:46:18,624: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:46:18,626: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 07:46:18,628: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 07:46:22,502: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 07:46:22,503: INFO: 2974174681]: Loading data...
[2025-10-02 07:46:22,531: INFO: 2974174681]: Generating embeddings via VectorStoreIndex...
[2025-10-02 07:46:26,661: INFO: 2974174681]: Saving VectorStoreIndex...
[2025-10-02 07:46:27,714: INFO: 2974174681]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-02 07:46:27,714: INFO: 3935594119]: Embeddings generation completed successfully.
[2025-10-02 07:53:52,169: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 07:53:52,286: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 07:53:52,286: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 07:53:52,309: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 07:53:53,644: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:53:53,646: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:53:53,647: INFO: helper]: Directory created at: artifacts
[2025-10-02 07:53:53,648: ERROR: 3104963246]: Error occurred: [Errno 2] No such file or directory: 'f:/ProjectAI/ChatSystem/../storage/docstore.json'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_3440\3104963246.py", line 7, in <module>
    response = retrieval.search(query)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_3440\2594017028.py", line 12, in search
    self.rebuild_storage_context()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_3440\2594017028.py", line 6, in rebuild_storage_context
    storage_context = StorageContext.from_defaults(persist_dir="../storage")
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\storage_context.py", line 113, in from_defaults
    docstore = docstore or SimpleDocumentStore.from_persist_dir(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\docstore\simple_docstore.py", line 62, in from_persist_dir
    return cls.from_persist_path(persist_path, namespace=namespace, fs=fs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\docstore\simple_docstore.py", line 81, in from_persist_path
    simple_kvstore = SimpleKVStore.from_persist_path(persist_path, fs=fs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\storage\kvstore\simple_kvstore.py", line 55, in from_persist_path
    with fs.open(persist_path, "rb") as f:
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\spec.py", line 1338, in open
    f = self._open(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\implementations\local.py", line 210, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\implementations\local.py", line 387, in __init__
    self._open()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\fsspec\implementations\local.py", line 392, in _open
    self.f = open(self.path, mode=self.mode)
FileNotFoundError: [Errno 2] No such file or directory: 'f:/ProjectAI/ChatSystem/../storage/docstore.json'
[2025-10-02 07:54:46,188: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:54:46,189: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:54:46,190: INFO: helper]: Directory created at: artifacts
[2025-10-02 07:54:48,109: INFO: loading]: Loading all indices.
[2025-10-02 07:54:48,727: ERROR: 3104963246]: Error occurred: [Errno 2] No such file or directory: 'artifacts\\embeddings\\embeddings.npy'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_3440\3104963246.py", line 7, in <module>
    response = retrieval.search(query)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_3440\4004961840.py", line 12, in search
    self.rebuild_storage_context()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_3440\4004961840.py", line 9, in rebuild_storage_context
    self.texts = np.load(Path(self.config.embeddings_file).with_suffix('.npy'), allow_pickle=True)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\numpy\lib\_npyio_impl.py", line 451, in load
    fid = stack.enter_context(open(os.fspath(file), "rb"))
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\embeddings\\embeddings.npy'
[2025-10-02 07:55:10,426: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:55:10,428: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:55:10,429: INFO: helper]: Directory created at: artifacts
[2025-10-02 07:55:12,301: INFO: loading]: Loading all indices.
[2025-10-02 07:55:13,166: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:55:13,166: INFO: _base_client]: Retrying request to /embeddings in 0.486358 seconds
[2025-10-02 07:55:14,295: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:55:14,295: INFO: _base_client]: Retrying request to /embeddings in 0.886699 seconds
[2025-10-02 07:55:15,514: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:55:15,514: INFO: _base_client]: Retrying request to /embeddings in 1.934533 seconds
[2025-10-02 07:55:17,795: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:55:17,795: INFO: _base_client]: Retrying request to /embeddings in 3.519571 seconds
[2025-10-02 07:55:21,637: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:55:21,644: INFO: _base_client]: Retrying request to /embeddings in 6.797449 seconds
[2025-10-02 07:55:28,963: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:55:28,963: INFO: _base_client]: Retrying request to /embeddings in 7.105024 seconds
[2025-10-02 07:55:36,627: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:55:36,627: INFO: _base_client]: Retrying request to /embeddings in 6.944068 seconds
[2025-10-02 07:55:44,101: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:55:44,101: INFO: _base_client]: Retrying request to /embeddings in 7.683637 seconds
[2025-10-02 07:55:52,286: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:55:52,293: INFO: _base_client]: Retrying request to /embeddings in 7.818514 seconds
[2025-10-02 07:56:00,700: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:56:00,703: INFO: _base_client]: Retrying request to /embeddings in 7.930694 seconds
[2025-10-02 07:56:09,112: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:56:09,112: WARNING: before_sleep]: Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._get_query_embedding.<locals>._retryable_get_embedding in 1.0 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.
[2025-10-02 07:56:10,578: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:56:10,578: INFO: _base_client]: Retrying request to /embeddings in 0.430160 seconds
[2025-10-02 07:56:11,318: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:56:11,318: INFO: _base_client]: Retrying request to /embeddings in 0.823658 seconds
[2025-10-02 07:56:12,455: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:56:12,455: INFO: _base_client]: Retrying request to /embeddings in 1.941893 seconds
[2025-10-02 07:56:14,867: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:56:14,867: INFO: _base_client]: Retrying request to /embeddings in 3.963840 seconds
[2025-10-02 07:56:19,147: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:56:19,149: INFO: _base_client]: Retrying request to /embeddings in 6.901203 seconds
[2025-10-02 07:56:26,613: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:56:26,614: INFO: _base_client]: Retrying request to /embeddings in 6.511780 seconds
[2025-10-02 07:56:33,583: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:56:33,598: INFO: _base_client]: Retrying request to /embeddings in 6.652146 seconds
[2025-10-02 07:56:40,700: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:56:40,700: INFO: _base_client]: Retrying request to /embeddings in 6.126795 seconds
[2025-10-02 07:56:47,270: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:56:47,271: INFO: _base_client]: Retrying request to /embeddings in 6.682968 seconds
[2025-10-02 07:56:54,434: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:56:54,436: INFO: _base_client]: Retrying request to /embeddings in 6.902259 seconds
[2025-10-02 07:57:01,814: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:57:01,816: ERROR: 3104963246]: Error occurred: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_3440\3104963246.py", line 7, in <module>
    response = retrieval.search(query)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_3440\3788607106.py", line 12, in search
    response = self.index.as_query_engine().query(query)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\base_query_engine.py", line 44, in query
    query_result = self._query(str_or_query_bundle)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\query_engine\retriever_query_engine.py", line 196, in _query
    nodes = self.retrieve(query_bundle)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\query_engine\retriever_query_engine.py", line 149, in retrieve
    nodes = self._retriever.retrieve(query_bundle)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\base_retriever.py", line 210, in retrieve
    nodes = self._retrieve(query_bundle)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\vector_store\retrievers\retriever.py", line 100, in _retrieve
    self._embed_model.get_agg_embedding_from_queries(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\embeddings\base.py", line 228, in get_agg_embedding_from_queries
    query_embeddings = [self.get_query_embedding(query) for query in queries]
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\embeddings\base.py", line 228, in <listcomp>
    query_embeddings = [self.get_query_embedding(query) for query in queries]
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\base\embeddings\base.py", line 149, in get_query_embedding
    query_embedding = self._get_query_embedding(query)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index_instrumentation\dispatcher.py", line 335, in wrapper
    result = func(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 402, in _get_query_embedding
    return _retryable_get_embedding()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 451, in result
    return self.__get_result()
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\concurrent\futures\_base.py", line 403, in __get_result
    raise self._exception
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 395, in _retryable_get_embedding
    return get_embedding(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\embeddings\openai\base.py", line 129, in get_embedding
    client.embeddings.create(input=[text], model=engine, **kwargs).data[0].embedding
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\resources\embeddings.py", line 132, in create
    return self._post(
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
[2025-10-02 07:57:06,969: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:57:06,970: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:57:06,971: INFO: helper]: Directory created at: artifacts
[2025-10-02 07:57:08,874: INFO: loading]: Loading all indices.
[2025-10-02 07:57:09,386: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:57:09,401: INFO: _base_client]: Retrying request to /embeddings in 0.490982 seconds
[2025-10-02 07:57:10,245: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:57:10,247: INFO: _base_client]: Retrying request to /embeddings in 0.836172 seconds
[2025-10-02 07:57:11,384: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:57:11,384: INFO: _base_client]: Retrying request to /embeddings in 1.879630 seconds
[2025-10-02 07:57:13,585: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:57:13,585: INFO: _base_client]: Retrying request to /embeddings in 3.626458 seconds
[2025-10-02 07:57:17,548: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:57:17,548: INFO: _base_client]: Retrying request to /embeddings in 7.512367 seconds
[2025-10-02 07:57:25,506: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:57:25,508: INFO: _base_client]: Retrying request to /embeddings in 7.644579 seconds
[2025-10-02 07:58:11,901: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 07:58:11,901: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 07:58:11,901: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 07:58:12,029: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 07:58:13,266: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 07:58:13,268: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 07:58:13,270: INFO: helper]: Directory created at: artifacts
[2025-10-02 07:58:15,227: INFO: loading]: Loading all indices.
[2025-10-02 07:58:16,802: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:58:16,802: INFO: _base_client]: Retrying request to /embeddings in 0.445366 seconds
[2025-10-02 07:58:17,559: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:58:17,560: INFO: _base_client]: Retrying request to /embeddings in 0.902756 seconds
[2025-10-02 07:58:18,773: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 07:58:18,773: INFO: _base_client]: Retrying request to /embeddings in 1.817470 seconds
[2025-10-02 08:00:48,231: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 08:00:48,232: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 08:00:48,232: INFO: helper]: Directory created at: artifacts
[2025-10-02 08:00:50,154: INFO: loading]: Loading all indices.
[2025-10-02 08:00:50,171: ERROR: 3104963246]: Error occurred: 'NoneType' object has no attribute 'as_query_engine'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_3180\3104963246.py", line 7, in <module>
    response = retrieval.search(query)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_3180\3240363509.py", line 12, in search
    response = self.index.as_query_engine().query(query)
AttributeError: 'NoneType' object has no attribute 'as_query_engine'
[2025-10-02 08:01:26,024: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 08:01:26,026: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 08:01:26,027: INFO: helper]: Directory created at: artifacts
[2025-10-02 08:01:27,933: INFO: loading]: Loading all indices.
[2025-10-02 08:01:28,407: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 08:01:28,409: INFO: _base_client]: Retrying request to /embeddings in 0.388303 seconds
[2025-10-02 08:01:29,165: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 08:01:29,165: INFO: _base_client]: Retrying request to /embeddings in 0.844198 seconds
[2025-10-02 08:01:30,325: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 08:01:30,325: INFO: _base_client]: Retrying request to /embeddings in 1.812346 seconds
[2025-10-02 08:01:32,447: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 08:01:32,447: INFO: _base_client]: Retrying request to /embeddings in 3.944114 seconds
[2025-10-02 08:04:42,861: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 08:04:42,863: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 08:04:42,864: INFO: helper]: Directory created at: artifacts
[2025-10-02 08:04:44,809: INFO: loading]: Loading all indices.
[2025-10-02 08:04:45,297: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 08:04:45,298: INFO: _base_client]: Retrying request to /embeddings in 0.434225 seconds
[2025-10-02 08:04:46,058: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 08:04:46,058: INFO: _base_client]: Retrying request to /embeddings in 0.783447 seconds
[2025-10-02 08:04:47,165: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 08:04:47,166: INFO: _base_client]: Retrying request to /embeddings in 1.669028 seconds
[2025-10-02 08:04:49,171: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 08:04:49,171: INFO: _base_client]: Retrying request to /embeddings in 3.192619 seconds
[2025-10-02 08:04:52,663: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 08:04:52,668: INFO: _base_client]: Retrying request to /embeddings in 7.075532 seconds
[2025-10-02 08:05:38,174: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 08:05:38,176: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 08:05:38,177: INFO: helper]: Directory created at: artifacts
[2025-10-02 08:05:40,086: INFO: loading]: Loading all indices.
[2025-10-02 08:05:40,609: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 08:05:40,609: INFO: _base_client]: Retrying request to /embeddings in 0.417495 seconds
[2025-10-02 08:05:41,308: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 08:05:41,308: INFO: _base_client]: Retrying request to /embeddings in 0.944371 seconds
[2025-10-02 08:05:42,593: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 08:05:42,594: INFO: _base_client]: Retrying request to /embeddings in 1.945124 seconds
[2025-10-02 10:15:10,624: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 10:15:10,624: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 10:15:10,624: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 10:15:10,741: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 10:15:11,961: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:15:11,969: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:15:11,971: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:15:13,872: INFO: loading]: Loading all indices.
[2025-10-02 10:15:15,808: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:15:15,809: INFO: _base_client]: Retrying request to /embeddings in 0.473562 seconds
[2025-10-02 10:15:17,165: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:15:17,165: INFO: _base_client]: Retrying request to /embeddings in 0.970280 seconds
[2025-10-02 10:15:18,800: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:15:18,800: INFO: _base_client]: Retrying request to /embeddings in 1.705824 seconds
[2025-10-02 10:15:33,866: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:15:33,867: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:15:33,868: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:15:35,731: INFO: loading]: Loading all indices.
[2025-10-02 10:15:36,488: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:15:36,490: INFO: _base_client]: Retrying request to /embeddings in 0.395539 seconds
[2025-10-02 10:15:37,219: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:15:37,220: INFO: _base_client]: Retrying request to /embeddings in 0.942006 seconds
[2025-10-02 10:15:38,468: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:15:38,470: INFO: _base_client]: Retrying request to /embeddings in 1.582071 seconds
[2025-10-02 10:24:41,341: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:24:41,343: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:24:41,343: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:24:43,269: INFO: loading]: Loading all indices.
[2025-10-02 10:24:43,748: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:24:43,748: INFO: _base_client]: Retrying request to /embeddings in 0.466642 seconds
[2025-10-02 10:24:45,500: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:24:45,502: INFO: _base_client]: Retrying request to /embeddings in 0.908592 seconds
[2025-10-02 10:24:46,712: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:24:46,712: INFO: _base_client]: Retrying request to /embeddings in 1.621861 seconds
[2025-10-02 10:24:48,978: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:24:48,978: INFO: _base_client]: Retrying request to /embeddings in 3.371652 seconds
[2025-10-02 10:26:37,585: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:26:37,586: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:26:37,587: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:26:39,434: INFO: loading]: Loading all indices.
[2025-10-02 10:26:40,194: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:26:40,194: INFO: _base_client]: Retrying request to /embeddings in 0.458348 seconds
[2025-10-02 10:26:41,200: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:26:41,201: INFO: _base_client]: Retrying request to /embeddings in 0.898140 seconds
[2025-10-02 10:26:42,419: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:26:42,421: INFO: _base_client]: Retrying request to /embeddings in 1.864880 seconds
[2025-10-02 10:26:44,580: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:26:44,580: INFO: _base_client]: Retrying request to /embeddings in 3.062150 seconds
[2025-10-02 10:28:05,550: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:28:05,551: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:28:05,552: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:28:07,482: INFO: loading]: Loading all indices.
[2025-10-02 10:28:22,637: INFO: _base_client]: Retrying request to /embeddings in 0.382614 seconds
[2025-10-02 10:28:23,506: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:28:23,507: INFO: _base_client]: Retrying request to /embeddings in 0.793643 seconds
[2025-10-02 10:28:24,827: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:28:24,829: INFO: _base_client]: Retrying request to /embeddings in 1.894738 seconds
[2025-10-02 10:28:27,030: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:28:27,030: INFO: _base_client]: Retrying request to /embeddings in 3.259032 seconds
[2025-10-02 10:28:30,579: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:28:30,582: INFO: _base_client]: Retrying request to /embeddings in 6.842719 seconds
[2025-10-02 10:28:51,798: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 10:28:51,801: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 10:28:51,801: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 10:28:51,939: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 10:28:53,099: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:28:53,099: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:28:53,099: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:28:54,999: INFO: loading]: Loading all indices.
[2025-10-02 10:28:56,470: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:28:56,470: INFO: _base_client]: Retrying request to /embeddings in 0.457761 seconds
[2025-10-02 10:28:57,219: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:28:57,219: INFO: _base_client]: Retrying request to /embeddings in 0.992948 seconds
[2025-10-02 10:28:58,504: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:28:58,505: INFO: _base_client]: Retrying request to /embeddings in 1.521293 seconds
[2025-10-02 10:29:00,328: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:00,328: INFO: _base_client]: Retrying request to /embeddings in 3.792029 seconds
[2025-10-02 10:29:04,409: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:04,410: INFO: _base_client]: Retrying request to /embeddings in 7.726292 seconds
[2025-10-02 10:29:12,612: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:12,615: INFO: _base_client]: Retrying request to /embeddings in 7.457606 seconds
[2025-10-02 10:29:20,523: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:20,524: INFO: _base_client]: Retrying request to /embeddings in 7.125946 seconds
[2025-10-02 10:29:28,145: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:28,147: INFO: _base_client]: Retrying request to /embeddings in 6.145778 seconds
[2025-10-02 10:29:34,768: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:34,783: INFO: _base_client]: Retrying request to /embeddings in 6.705007 seconds
[2025-10-02 10:29:41,982: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:41,983: INFO: _base_client]: Retrying request to /embeddings in 7.647716 seconds
[2025-10-02 10:29:50,134: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:50,136: WARNING: before_sleep]: Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._get_query_embedding.<locals>._retryable_get_embedding in 1.0 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.
[2025-10-02 10:29:51,864: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:51,864: INFO: _base_client]: Retrying request to /embeddings in 0.432400 seconds
[2025-10-02 10:29:52,621: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:52,625: INFO: _base_client]: Retrying request to /embeddings in 0.970621 seconds
[2025-10-02 10:29:53,888: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:53,890: INFO: _base_client]: Retrying request to /embeddings in 1.575023 seconds
[2025-10-02 10:29:55,795: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:55,800: INFO: _base_client]: Retrying request to /embeddings in 3.184816 seconds
[2025-10-02 10:29:59,313: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:29:59,315: INFO: _base_client]: Retrying request to /embeddings in 6.367779 seconds
[2025-10-02 10:30:06,168: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:30:06,170: INFO: _base_client]: Retrying request to /embeddings in 7.442517 seconds
[2025-10-02 10:30:14,479: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:30:14,480: INFO: _base_client]: Retrying request to /embeddings in 6.032503 seconds
[2025-10-02 10:32:23,614: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:32:23,616: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:32:23,617: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:32:25,554: ERROR: 2128669561]: Error occurred: name 'HuggingFaceEmbedding' is not defined
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26840\2128669561.py", line 6, in <module>
    retrieval = Retrieval(config=retrieval_config)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26840\586126968.py", line 5, in __init__
    embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-small-en-v1.5")
NameError: name 'HuggingFaceEmbedding' is not defined
[2025-10-02 10:32:34,119: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:32:34,120: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:32:34,121: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:32:36,018: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 10:32:40,174: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 10:32:40,175: ERROR: 2128669561]: Error occurred: 'StorageContext' object is not iterable
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26840\2128669561.py", line 6, in <module>
    retrieval = Retrieval(config=retrieval_config)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26840\586126968.py", line 6, in __init__
    self.index = VectorStoreIndex.from_documents(storage_context, embed_model=embed_model)
  File "c:\Users\namnh\miniconda3\envs\ChatBoxAI\lib\site-packages\llama_index\core\indices\base.py", line 112, in from_documents
    for doc in documents:
TypeError: 'StorageContext' object is not iterable
[2025-10-02 10:34:18,220: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:34:18,221: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:34:18,222: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:34:20,141: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 10:34:23,998: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 10:34:23,998: ERROR: 2128669561]: Error occurred: type object 'VectorStoreIndex' has no attribute 'load_from_storage'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26840\2128669561.py", line 6, in <module>
    retrieval = Retrieval(config=retrieval_config)
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_26840\556216152.py", line 6, in __init__
    self.index = VectorStoreIndex.load_from_storage(storage_context, embed_model=embed_model)
AttributeError: type object 'VectorStoreIndex' has no attribute 'load_from_storage'
[2025-10-02 10:40:32,045: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:40:32,046: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:40:32,047: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:40:33,914: INFO: loading]: Loading all indices.
[2025-10-02 10:40:34,781: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:40:34,781: INFO: _base_client]: Retrying request to /embeddings in 0.378699 seconds
[2025-10-02 10:40:35,492: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:40:35,492: INFO: _base_client]: Retrying request to /embeddings in 0.967286 seconds
[2025-10-02 10:40:36,854: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:40:36,856: INFO: _base_client]: Retrying request to /embeddings in 1.896274 seconds
[2025-10-02 10:40:39,156: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:40:39,156: INFO: _base_client]: Retrying request to /embeddings in 3.881554 seconds
[2025-10-02 10:40:43,318: INFO: _client]: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 429 Too Many Requests"
[2025-10-02 10:40:43,318: INFO: _base_client]: Retrying request to /embeddings in 6.329946 seconds
[2025-10-02 10:40:57,901: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:40:57,903: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:40:57,904: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:40:59,746: INFO: loading]: Loading all indices.
[2025-10-02 10:40:59,762: INFO: 2128669561]: Retrieval completed successfully.
[2025-10-02 10:42:08,753: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 10:42:08,753: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 10:42:08,753: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 10:42:08,864: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 10:42:10,119: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:42:10,120: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:42:10,121: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 10:42:10,122: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 10:42:10,125: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 10:42:14,731: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 10:42:14,731: INFO: 2974174681]: Loading data...
[2025-10-02 10:42:14,786: INFO: 2974174681]: Generating embeddings via VectorStoreIndex...
[2025-10-02 10:42:18,809: INFO: 2974174681]: Saving VectorStoreIndex...
[2025-10-02 10:42:19,850: INFO: 2974174681]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-02 10:42:19,850: INFO: 3935594119]: Embeddings generation completed successfully.
[2025-10-02 10:42:45,180: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 10:42:45,180: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 10:42:45,180: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 10:42:45,310: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 10:42:46,559: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:42:46,562: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:42:46,562: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:42:48,578: INFO: loading]: Loading all indices.
[2025-10-02 10:42:49,160: INFO: 2128669561]: Retrieval completed successfully.
[2025-10-02 10:44:27,260: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 10:44:27,267: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 10:44:27,267: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 10:44:27,396: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 10:44:28,754: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:44:28,757: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:44:28,758: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 10:44:28,759: INFO: helper]: Directory created at: artifacts/embeddings
[2025-10-02 10:44:28,763: INFO: SentenceTransformer]: Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
[2025-10-02 10:44:32,997: INFO: SentenceTransformer]: 1 prompt is loaded, with the key: query
[2025-10-02 10:44:32,997: INFO: 2974174681]: Loading data...
[2025-10-02 10:44:33,031: INFO: 2974174681]: Generating embeddings via VectorStoreIndex...
[2025-10-02 10:44:37,083: INFO: 2974174681]: Saving VectorStoreIndex...
[2025-10-02 10:44:38,116: INFO: 2974174681]: Embeddings saved to artifacts\embeddings\embeddings.index
[2025-10-02 10:44:38,117: INFO: 3935594119]: Embeddings generation completed successfully.
[2025-10-02 10:44:52,879: INFO: loader]: Loading faiss with AVX512 support.
[2025-10-02 10:44:52,879: INFO: loader]: Could not load library with AVX512 support due to:
ModuleNotFoundError("No module named 'faiss.swigfaiss_avx512'")
[2025-10-02 10:44:52,879: INFO: loader]: Loading faiss with AVX2 support.
[2025-10-02 10:44:52,992: INFO: loader]: Successfully loaded faiss with AVX2 support.
[2025-10-02 10:44:54,383: INFO: helper]: YAML file config\config.yaml loaded successfully.
[2025-10-02 10:44:54,391: INFO: helper]: YAML file params.yaml loaded successfully.
[2025-10-02 10:44:54,393: INFO: helper]: Directory created at: artifacts
[2025-10-02 10:44:56,479: INFO: loading]: Loading all indices.
[2025-10-02 10:44:57,064: INFO: 2128669561]: Retrieval completed successfully.
