{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a481e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb9ffae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\ProjectAI\\\\ChatSystem'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6fb0343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed3beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GEMINI_API_KEY\"] = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea9b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class RetrievalConfig:\n",
    "    top_k: int \n",
    "    model_name: str\n",
    "    embeddings_file: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bc54ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ChatBoxSystem.constants import *\n",
    "from ChatBoxSystem.utils.helper import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f31c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: Path = CONFIG_FILE_PATH,\n",
    "        params_filepath: Path = PARAMS_FILE_PATH,\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_retrieval_config(self) -> RetrievalConfig:\n",
    "        retrieval_config = self.config.retrieval\n",
    "        retrieval_config = RetrievalConfig(\n",
    "            top_k=retrieval_config.top_k,\n",
    "            model_name=self.config.embeddings.model_name,\n",
    "            embeddings_file=self.config.embeddings.embeddings_file\n",
    "        )\n",
    "        return retrieval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50882310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namnh\\miniconda3\\envs\\ChatBoxAI\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-02 10:44:52,879: INFO: loader]: Loading faiss with AVX512 support.\n",
      "[2025-10-02 10:44:52,879: INFO: loader]: Could not load library with AVX512 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx512'\")\n",
      "[2025-10-02 10:44:52,879: INFO: loader]: Loading faiss with AVX2 support.\n",
      "[2025-10-02 10:44:52,992: INFO: loader]: Successfully loaded faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13592c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retrieval:\n",
    "    def __init__(self, config: RetrievalConfig):\n",
    "        self.config = config\n",
    "        self.model = SentenceTransformer(self.config.model_name)\n",
    "        self.index = faiss.read_index(self.config.embeddings_file)\n",
    "        embeddings_file = Path(self.config.embeddings_file)\n",
    "        self.texts = np.load(embeddings_file.with_suffix('.npy'), allow_pickle=True)\n",
    "\n",
    "    def search(self, query: str):\n",
    "        # Implement search logic here\n",
    "        query_emb = self.model.encode([query], convert_to_numpy=True)\n",
    "        query_emb = normalize(query_emb)\n",
    "        distances, indices = self.index.search(query_emb.astype(\"float32\"), self.config.top_k)\n",
    "        results = [self.texts[i] for i in indices[0]]\n",
    "        return results, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ada710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.indices.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core import StorageContext, load_index_from_storage, VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "441ba295",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retrieval:\n",
    "    def __init__(self, config: RetrievalConfig):\n",
    "        self.config = config\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "        self.index = load_index_from_storage(storage_context)\n",
    "\n",
    "    def search(self, query: str):\n",
    "        retrievel = VectorIndexRetriever(index=self.index, similarity_top_k=self.config.top_k)\n",
    "        # top_nodes = retrievel.retrieve(query)\n",
    "        print(type(self.index._embed_model))\n",
    "        print(f\"Top-{self.config.top_k} documents for query: '{query}'\\n\")\n",
    "        # for i, node in enumerate(top_nodes, 1):\n",
    "        #     print(f\"{i}. {node.node.get_text()}\\n\")\n",
    "        # query_engine = RetrieverQueryEngine(retriever=retrievel)\n",
    "        # response = query_engine.query(query)\n",
    "        # if hasattr(response, \"source_nodes\"):\n",
    "        #     print(f\"Top-{self.config.top_k} results:\")\n",
    "        #     for i, node in enumerate(response.source_nodes, 1):\n",
    "        #         print(f\"{i}. {node.node.get_text()}\\n\")\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41880d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ChatBoxSystem import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de2a0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Do you like working in teams?\"\n",
    "\n",
    "# try:\n",
    "#     config = ConfigurationManager()\n",
    "#     retrieval_config = config.get_retrieval_config()\n",
    "\n",
    "#     retrieval = Retrieval(config=retrieval_config)\n",
    "#     results, distances = retrieval.search(query)\n",
    "\n",
    "#     for i, (res, dist) in enumerate(zip(results, distances[0])):\n",
    "#         print(f\"Result {i+1}: {res} (Distance: {dist})\")\n",
    "#     logger.info(\"Retrieval completed successfully.\")\n",
    "# except Exception as e:\n",
    "#     logger.exception(f\"Error occurred: {e}\")\n",
    "#     raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8304606e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-02 10:44:54,383: INFO: helper]: YAML file config\\config.yaml loaded successfully.\n",
      "[2025-10-02 10:44:54,391: INFO: helper]: YAML file params.yaml loaded successfully.\n",
      "[2025-10-02 10:44:54,393: INFO: helper]: Directory created at: artifacts\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage\\docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage\\index_store.json.\n",
      "[2025-10-02 10:44:56,479: INFO: loading]: Loading all indices.\n",
      "<class 'llama_index.embeddings.openai.base.OpenAIEmbedding'>\n",
      "Top-3 documents for query: 'Do you like working in teams?'\n",
      "\n",
      "None\n",
      "[2025-10-02 10:44:57,064: INFO: 2128669561]: Retrieval completed successfully.\n"
     ]
    }
   ],
   "source": [
    "query = \"Do you like working in teams?\"\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    retrieval_config = config.get_retrieval_config()\n",
    "\n",
    "    retrieval = Retrieval(config=retrieval_config)\n",
    "    response = retrieval.search(query)\n",
    "    print(response)\n",
    "    logger.info(\"Retrieval completed successfully.\")\n",
    "except Exception as e:\n",
    "    logger.exception(f\"Error occurred: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6366a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatBoxAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
